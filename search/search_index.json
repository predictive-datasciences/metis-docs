{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Metis Documentation","text":"<p>Metis is a modern, multi-tenant SAAS platform designed for financial institutions, built with modularity, security, and scalability at its core.</p>"},{"location":"#quick-navigation","title":"\ud83d\ude80 Quick Navigation","text":""},{"location":"#technical-architecture","title":"\ud83c\udfd7\ufe0f Technical Architecture","text":"<ul> <li>Introduction to Metis - Platform overview and core concepts</li> <li>Data Flow - Request handling, authentication, and event processing</li> <li>Data Storage - Database design and storage patterns</li> <li>Data Processing - ML pipelines and business logic processing</li> </ul>"},{"location":"#coding-guidelines","title":"\ud83d\udcbb Coding Guidelines","text":"<ul> <li>Python Guidelines - Python coding standards and best practices</li> <li>Go Guidelines - Go coding standards and conventions</li> <li>Repository Structure - Project organization and file structure</li> <li>Testing - Testing strategies and implementation</li> <li>Error Handling - Error management patterns</li> </ul>"},{"location":"#operations-monitoring","title":"\ud83d\udd27 Operations &amp; Monitoring","text":"<ul> <li>Logging - Logging standards and implementation</li> <li>Monitoring - System monitoring and observability</li> <li>Metrics - Performance metrics and KPIs</li> <li>Tracing - Distributed tracing implementation</li> <li>Configuration - Configuration management</li> </ul>"},{"location":"#platform-overview","title":"\ud83c\udfaf Platform Overview","text":"<p>Metis is built around three core architectural spaces:</p> <ul> <li>\ud83c\udfaf Core App Space: Plugin-based client-specific functionality</li> <li>\ud83e\udde0 ML Space: Machine learning models and data processing</li> <li>\u2699\ufe0f Infrastructure: Shared utilities and infrastructure components</li> </ul>"},{"location":"#getting-started","title":"\ud83d\ude80 Getting Started","text":"<ol> <li>Understand the Architecture: Start with Introduction to Metis</li> <li>Learn Data Flow: Review Data Flow patterns</li> <li>Follow Coding Standards: Check Go Guidelines and Python Guidelines</li> <li>Set Up Development: Follow Repository Structure guidelines</li> </ol>"},{"location":"#documentation-structure","title":"\ud83d\udcda Documentation Structure","text":"<p>This documentation is organized to support both developers and architects:</p> <ul> <li>Architecture docs provide system design and technical decisions</li> <li>Coding guidelines ensure consistent development practices</li> <li>Operations docs cover monitoring, logging, and maintenance</li> </ul> <p>This documentation is a living resource that evolves with the Metis platform. Contributions and feedback are welcome.</p>"},{"location":"architecture-overview/","title":"Introduction to Metis Platform","text":"<p>This document introduces the high-level architecture of our SAAS platform, which we've internally named Metis. The platform helps financial institutions streamline operations through intelligent automation, machine learning, and configurable business processes.</p> <p>We'll define components in logical space context to help visualize future development and understand our product design and pluggable interface. The grouping may or may not indicate the exact architecture and deployment plan, but helps understand the motivation behind our product design.</p> <p></p>"},{"location":"architecture-overview/#platform-architecture","title":"\ud83c\udfd7\ufe0f Platform Architecture","text":"<p>The Metis platform is organized into three logical spaces:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        METIS PLATFORM                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83c\udfaf CORE APP SPACE                                             \u2502\n\u2502  \u251c\u2500 Core App Interface (Single Entry Point)                    \u2502\n\u2502  \u251c\u2500 LOS (Loan Origination System)                             \u2502\n\u2502  \u251c\u2500 Rules Engine                                               \u2502\n\u2502  \u251c\u2500 Fraud Score Engine                                         \u2502\n\u2502  \u2514\u2500 Client-Specific Plugins                                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83e\udde0 ML SPACE                                                   \u2502\n\u2502  \u251c\u2500 Common Models (OCR, Classification)                        \u2502\n\u2502  \u251c\u2500 Client-Specific Models (Risk, Fraud)                       \u2502\n\u2502  \u2514\u2500 Model Registry &amp; Versioning                                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83d\udee0\ufe0f UTIL &amp; INFRASTRUCTURE COMPONENTS                          \u2502\n\u2502  \u251c\u2500 Temporal (Workflow Orchestration)                          \u2502\n\u2502  \u251c\u2500 PostgreSQL (Primary Database)                              \u2502\n\u2502  \u251c\u2500 S3 (Object Storage)                                        \u2502\n\u2502  \u251c\u2500 RabbitMQ (Message Queue)                                   \u2502\n\u2502  \u251c\u2500 DuckDB (Analytics Database)                                \u2502\n\u2502  \u2514\u2500 Apache Superset (Dashboards)                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture-overview/#core-app-space","title":"\ud83c\udfaf Core App Space","text":"<p>All components within this are client specific plugins. The Core App Interface is how any UI/User/etc communicates with core app space.</p>"},{"location":"architecture-overview/#core-app-interface","title":"Core App Interface","text":"<ul> <li>Single entry point for all external communication</li> <li>Installs different plugins based on client needs</li> <li>Example: Some clients need LOS + Rules Engine + Fraud Score Engine (all three can be independently wired up)</li> <li>As new clients come up with new features, we select plugins (or build new plugins) and tie them together</li> </ul>"},{"location":"architecture-overview/#key-plugins","title":"Key Plugins","text":"<p>LOS (Loan Origination System) - Complete loan application lifecycle management - Document collection and verification - Integration with external bureaus</p> <p>Rules Engine - Client-specific business logic without code changes - Configurable rules through configuration - Real-time rule evaluation</p> <p>Fraud Score Engine - Advanced fraud detection combining rule-based and ML approaches - Document verification and identity checks - ML-based fraud probability scoring</p>"},{"location":"architecture-overview/#ml-space","title":"\ud83e\udde0 ML Space","text":"<p>These are the underlying models and preprocessors for data that needs to be transformed via ML models. Components in this layer are triggered by core app space. The segregation allows developing both spaces independently and expose the core space to outside world.</p>"},{"location":"architecture-overview/#two-types-of-components","title":"Two Types of Components:","text":""},{"location":"architecture-overview/#1-common-models","title":"1. Common Models","text":"<p>OCR Engine - Input: Image \u2192 Output: Well structured data - Supports: PAN Cards, Aadhaar, Bank Statements, Salary Slips, ITR Documents</p> <p>Document Classification - Automatically identifies document types from uploaded images - Determines appropriate processing pipeline</p>"},{"location":"architecture-overview/#2-client-specific-models","title":"2. Client Specific Models","text":"<p>Risk Assessment Models - Client-specific risk models trained on their historical data - Example: Client specific risk models for probability of default</p>"},{"location":"architecture-overview/#util-infrastructure-components","title":"\ud83d\udee0\ufe0f Util &amp; Infrastructure Components","text":"<p>All components are either helper servers or cloud resources. Core app interface talks to this layer for authentication, log ingestion, monitoring data sampling, queue management, DB storage etc.</p>"},{"location":"architecture-overview/#component-definitions","title":"Component Definitions:","text":"<p>Temporal - Workflow orchestration tool - Widely used to define client specific business use cases and processes - Handles complex business workflows with reliability</p> <p>PostgreSQL - Our main DB - Relational DB but also good with JSON querying - Extension capabilities like direct geo queries, vector DB extension etc - Multi-tenant support with row-level security</p> <p>S3 - AWS cloud object store with lots of uses - Primary usage: Store images, files, etc as objects - Logs, events generated throughout our process stored here - Can be queried later for aggregate business analytics, alerting, model storage</p> <p>RabbitMQ - Queue of our choice for all asynchronous activities - Pushing events (for near real time ingestion) - Async processing result mapping - Can be reused for high volume, low ticket size clients</p> <p>DuckDB - Columnar embedded Database (uses server resources to compute) - All aggregate queries can be put here - Scales very well at lower volumes - Combines data in disk + archived S3 data to analyze things</p> <p>Apache Superset - Client specific dashboards to visualize query results from DuckDB/Postgres/any DB - Can add custom views with minor tweaks to open source solution</p>"},{"location":"architecture-overview/#sample-scenario","title":"\ud83d\udd04 Sample Scenario","text":"<p>Client A has signed up for LOS + Rules Engine (includes models). Here's the bureau pull and underwriting flow:</p> <pre><code>sequenceDiagram\n    box transparent PDS and Client Servers\n        participant U as UI\n        participant L as Core Space\n        participant P as PostgreSQL\n        participant S3 as S3 Storage\n        participant RE as Rules Engine\n        participant M as ML Space\n    end\n\n    box yellow External Systems\n        participant E as Bureau Provider\n    end\n\n    U-&gt;&gt;+L: Gives permission to pull bureau data\n    L-&gt;&gt;+E: Asks to pull bureau data\n    E-&gt;&gt;-L: Sends bureau data\n    L-&gt;&gt;+S3: Stores bureau data in S3\n    S3-&gt;&gt;-L: Returns S3 location/link of stored data\n    L-&gt;&gt;+P: Parse, store and update application state\n    P-&gt;&gt;-L: Acknowledges the update\n    L-&gt;&gt;-U: Asks to move forward\n\n    Note right of U: After few more steps when rules engine needs to be triggered\n\n    U-&gt;&gt;+L: Asks to compute offer\n    L-&gt;&gt;+P: Check if bureau pull was successfully done\n\n    alt Bureau pull not done\n        P-&gt;&gt;-L: Not allowed\n        L-&gt;&gt;-U: Asks UI to complete bureau pull and retry\n    else Bureau pull completed\n        P-&gt;&gt;+L: Move ahead\n        L-&gt;&gt;+M: Model inference\n        M-&gt;&gt;-L: Returns scores/values\n        L-&gt;&gt;+RE: Plugs values into deterministic rules engine\n        RE-&gt;&gt;-L: Returns detailed underwriting profile output\n        L-&gt;&gt;-U: Asks UI to proceed with next steps\n    end\n</code></pre>"},{"location":"architecture-overview/#platform-benefits","title":"\ud83c\udfaf Platform Benefits","text":"<p>The combination of these components allows us to add new features (or plugin products) in any combination. These plugins can be sold to our clients based on their specific needs.</p> <p>Key Advantages: - Modular: Mix and match components based on client requirements - Scalable: Each component scales independently - Customizable: Client-specific models and rules - Rapid Deployment: Quick client onboarding</p>"},{"location":"architecture-part-1/","title":"Metis Platform Architecture - Part 1: Data Flow","text":"<p>Part 1 of 3: This document focuses specifically on data flow patterns within the Metis platform. For complete architectural context, refer to the main architecture document and upcoming parts on storage and processing.</p>"},{"location":"architecture-part-1/#introduction","title":"\ud83c\udf0a Introduction","text":"<p>Data flow being core to Metis platform, orchestrating how information moves through our multi-tenant SAAS architecture. This document provides a comprehensive overview of request handling, authentication, state management, and event-driven processing patterns that enable our platform to serve multiple clients efficiently and securely.</p> <p>Our data flow architecture is designed around two fundamental patterns:</p> <ul> <li>Read Flows: Query and retrieval operations</li> <li>Write Flows: State-changing operations with complex orchestration</li> </ul>"},{"location":"architecture-part-1/#data-flow-architecture-overview","title":"\ud83c\udfd7\ufe0f Data Flow Architecture Overview","text":"<p>The below diagram shows how data flows in our multi-tenant architecture -</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    METIS DATA FLOW ARCHITECTURE                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83c\udf10 ENTRY LAYER                                                \u2502\n\u2502  \u251c\u2500 NGINX (Reverse Proxy)                                      \u2502\n\u2502  \u2514\u2500 Load Balancing &amp; SSL Termination                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83c\udfe2 TENANT LAYER                                               \u2502\n\u2502  \u251c\u2500 Client Container 1 \u251c\u2500 Client Container 2 \u251c\u2500 Client Container N \u2502\n\u2502  \u2514\u2500 Isolated tenant-specific processing                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83d\udd10 AUTHENTICATION LAYER                                        \u2502\n\u2502  \u251c\u2500 SuperTokens Server                                          \u2502\n\u2502  \u2514\u2500 Token Management &amp; Validation                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83d\udd04 ORCHESTRATION LAYER                                         \u2502\n\u2502  \u251c\u2500 State Machine Validation                                    \u2502\n\u2502  \u251c\u2500 Temporal Workflows                                          \u2502\n\u2502  \u2514\u2500 Event-Driven Processing                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83d\udcbe SHARED INFRASTRUCTURE                                       \u2502\n\u2502  \u251c\u2500 Multi-tenant Database                                       \u2502\n\u2502  \u251c\u2500 Common ML Services                                          \u2502\n\u2502  \u2514\u2500 Message Queues &amp; Storage                                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture-part-1/#entry-point-request-routing","title":"\ud83d\udeaa Entry Point &amp; Request Routing","text":""},{"location":"architecture-part-1/#nginx-reverse-proxy","title":"NGINX Reverse Proxy","text":"<p>Our platform entry point handles all incoming requests through a centralized reverse proxy:</p>"},{"location":"architecture-part-1/#key-responsibilities","title":"Key Responsibilities:","text":"<ul> <li>SSL Termination: Secure HTTPS handling</li> <li>Load Balancing: Distribute requests across tenant containers</li> <li>Request Routing: Direct requests to appropriate client containers</li> <li>Rate Limiting: Protect against abuse and ensure fair usage</li> <li>Static Content: Serve static assets efficiently</li> </ul>"},{"location":"architecture-part-1/#routing-logic","title":"Routing Logic:","text":"<pre><code>Incoming Request \u2192 NGINX \u2192 Client Container Selection \u2192 Authentication \u2192 Processing\n</code></pre>"},{"location":"architecture-part-1/#multi-tenant-container-architecture","title":"Multi-Tenant Container Architecture","text":"<ul> <li>N Clients = N Containers: Each client gets dedicated container isolation</li> <li>Shared Infrastructure: All containers access common multi-tenant components</li> <li>Resource Isolation: Prevents client interference while sharing infrastructure costs</li> </ul>"},{"location":"architecture-part-1/#authentication-authorization-flow","title":"\ud83d\udd10 Authentication &amp; Authorization Flow","text":""},{"location":"architecture-part-1/#token-based-security-model","title":"Token-Based Security Model","text":"<p>Our platform implements a comprehensive token-based authentication system using SuperTokens:</p> <pre><code>sequenceDiagram\n    participant C as Client/UI\n    participant N as NGINX\n    participant CC as Client Container\n    participant ST as SuperTokens\n    participant DB as Database\n\n    Note over C,DB: Authentication Flow\n\n    C-&gt;&gt;+N: Request with credentials\n    N-&gt;&gt;+CC: Route to tenant container\n    CC-&gt;&gt;+ST: Validate credentials\n    ST-&gt;&gt;+DB: Check user credentials\n    DB-&gt;&gt;-ST: Return user data\n    ST-&gt;&gt;-CC: Generate JWT token\n    CC-&gt;&gt;-N: Return token\n    N-&gt;&gt;-C: Authentication successful\n\n    Note over C,DB: Subsequent API Calls\n\n    C-&gt;&gt;+N: API request with token\n    N-&gt;&gt;+CC: Route with token\n    CC-&gt;&gt;+ST: Validate token\n    ST-&gt;&gt;-CC: Token validation result\n    CC-&gt;&gt;-N: Process request or reject\n    N-&gt;&gt;-C: API response\n</code></pre>"},{"location":"architecture-part-1/#token-generation-methods","title":"Token Generation Methods","text":""},{"location":"architecture-part-1/#1-app-login","title":"1. App Login \ud83d\udd11","text":"<ul> <li>User Authentication: Username/password login</li> <li>Session Management: Persistent login sessions</li> <li>Token Refresh: Automatic token renewal</li> </ul>"},{"location":"architecture-part-1/#2-agent-login","title":"2. Agent Login \ud83d\udc65","text":"<ul> <li>Agent Portal: Dedicated agent interface</li> <li>Role-Based Access: Different permission levels</li> <li>Audit Trail: Track agent actions</li> </ul>"},{"location":"architecture-part-1/#3-server-to-server-s2s","title":"3. Server-to-Server (S2S) \ud83d\udd17","text":"<ul> <li>API Keys: Access key and secret pairs</li> <li>Service Authentication: Backend service integration</li> <li>Programmatic Access: Automated system interactions</li> </ul>"},{"location":"architecture-part-1/#security-validation-pipeline","title":"Security Validation Pipeline","text":"<p>Every API call follows this security validation sequence: 1. Token Extraction: Extract token from request headers 2. Token Validation: Verify token authenticity with SuperTokens 3. Authorization Check: Validate user permissions for requested resource 4. Request Processing: Proceed with business logic if authorized</p>"},{"location":"architecture-part-1/#data-flow-patterns","title":"\ud83d\udcca Data Flow Patterns","text":""},{"location":"architecture-part-1/#read-flows","title":"Read Flows \ud83d\udcd6","text":"<p>Read flows handle query and retrieval operations with minimal complexity:</p> <pre><code>flowchart TD\n    A[API Request] --&gt; B[Authentication]\n    B --&gt; C[Query Validation]\n    C --&gt; D[Database Query]\n    D --&gt; E[Result Processing]\n    E --&gt; F[Response]\n\n    style A fill:#e1f5fe\n    style F fill:#e8f5e8\n</code></pre>"},{"location":"architecture-part-1/#characteristics","title":"Characteristics:","text":"<ul> <li>Stateless Operations: No system state changes</li> <li>Database-Heavy: Primary processing in database layer</li> <li>Fast Response: Optimized for quick data retrieval</li> <li>Cacheable: Future caching implementation for high-frequency queries</li> </ul>"},{"location":"architecture-part-1/#examples","title":"Examples:","text":"<ul> <li>Fetch list of banks</li> <li>Check user progress</li> <li>Retrieve transaction history</li> <li>Generate reports</li> </ul>"},{"location":"architecture-part-1/#write-flows","title":"Write Flows \u270d\ufe0f","text":"<p>Write flows handle complex state-changing operations with sophisticated orchestration:</p> <pre><code>sequenceDiagram\n    participant C as Client\n    participant CC as Client Container\n    participant SM as State Machine\n    participant TW as Temporal Workflow\n    participant Q as Response Queue\n    participant ML as ML Services\n    participant DB as Database\n    participant S3 as S3 Storage\n\n    Note over C,S3: Write Flow Processing\n\n    C-&gt;&gt;+CC: Write API Request\n    CC-&gt;&gt;CC: Authentication &amp; Authorization\n    CC-&gt;&gt;CC: Schema Validation\n    CC-&gt;&gt;+SM: Validate Current State\n    SM-&gt;&gt;-CC: State Validation Result\n\n    alt Invalid State\n        CC-&gt;&gt;-C: State Error Response\n    else Valid State\n        CC-&gt;&gt;CC: Preprocessing (File Upload to S3)\n        CC-&gt;&gt;+TW: Trigger Workflow\n        TW-&gt;&gt;-CC: Workflow ID\n        CC-&gt;&gt;+Q: Listen for Response\n\n        Note over TW,S3: Async Workflow Processing\n        TW-&gt;&gt;+ML: ML Processing Request\n        ML-&gt;&gt;-TW: ML Results\n        TW-&gt;&gt;+DB: Store Results\n        DB-&gt;&gt;-TW: Confirmation\n        TW-&gt;&gt;+Q: Publish Result\n\n        Q-&gt;&gt;-CC: Workflow Response\n        CC-&gt;&gt;-C: Final API Response\n    end\n</code></pre>"},{"location":"architecture-part-1/#state-machine-management","title":"\ud83d\udd04 State Machine Management","text":""},{"location":"architecture-part-1/#finite-state-machine-implementation","title":"Finite State Machine Implementation","text":"<p>We use qmuntal/stateless library to implement configurable state machines for each tenant:</p>"},{"location":"architecture-part-1/#sample-state-configuration","title":"Sample State Configuration:","text":"<pre><code>{\n      \"states\": [\n        {\n        \"state_name\": \"provide_personal_details\",\n      \"valid_next_states\": [\"provide_pan_details\"],\n      \"required_fields\": [\"name\", \"email\", \"phone\"],\n      \"validation_rules\": [\"email_format\", \"phone_format\"]\n        },\n        {\n        \"state_name\": \"provide_pan_details\",\n      \"valid_next_states\": [\"provide_aadhar_details\"],\n      \"required_fields\": [\"pan_number\", \"pan_image\"],\n      \"validation_rules\": [\"pan_format\", \"image_size\"]\n        },\n        {\n        \"state_name\": \"provide_aadhar_details\",\n      \"valid_next_states\": [\"document_verification\", \"completed\"],\n      \"required_fields\": [\"aadhar_number\", \"aadhar_image\"],\n      \"validation_rules\": [\"aadhar_format\", \"image_quality\"]\n    },\n    {\n      \"state_name\": \"document_verification\",\n      \"valid_next_states\": [\"completed\", \"provide_additional_docs\"],\n      \"automated\": true,\n      \"timeout\": \"5m\"\n    },\n    {\n      \"state_name\": \"completed\",\n      \"valid_next_states\": [],\n      \"final_state\": true\n        }\n      ]\n      }\n      ```\n\n#### State Machine Benefits:\n- **Validation**: Both UI and backend validate state transitions\n- **Consistency**: Ensures proper workflow progression\n- **Flexibility**: Configurable per tenant requirements\n- **Debugging**: Clear state tracking for troubleshooting\n\n---\n\n## \u26a1 Workflow Orchestration with Temporal\n\n### **Asynchronous Processing Architecture**\n\nOur platform leverages **Temporal** for complex business process orchestration:\n\n#### Workflow Execution Pattern:\n```mermaid\nflowchart TD\n    A[API Request] --&gt; B[Workflow Trigger]\n    B --&gt; C[Workflow Execution]\n    C --&gt; D[Response Queue]\n    D --&gt; E[Queue Listener]\n    E --&gt; F[Response Matching]\n    F --&gt; G{Workflow ID Match?}\n    G --&gt;|No| H[NACK &amp; Requeue]\n    G --&gt;|Yes| I[Process Response]\n    I --&gt; J[API Response]\n    H --&gt; E\n\n    style A fill:#e1f5fe\n    style J fill:#e8f5e8\n    style H fill:#ffebee\n</code></pre>"},{"location":"architecture-part-1/#key-features","title":"Key Features:","text":""},{"location":"architecture-part-1/#1-reliability-fault-tolerance","title":"1. Reliability &amp; Fault Tolerance","text":"<ul> <li>Automatic Retries: Built-in retry mechanisms</li> <li>State Persistence: Workflow state survives failures</li> <li>Resumption: Continue from last successful step</li> </ul>"},{"location":"architecture-part-1/#2-event-loop-architecture","title":"2. Event Loop Architecture","text":"<ul> <li>Async Processing: Non-blocking workflow execution</li> <li>Queue-Based Communication: Decoupled request/response</li> <li>Timeout Management: 5-minute TTL with DLQ fallback</li> </ul>"},{"location":"architecture-part-1/#3-third-party-integration","title":"3. Third-Party Integration","text":"<ul> <li>Waterfall Pattern: Sequential API calls with fallbacks</li> <li>Retry Logic: Configurable retry strategies</li> <li>Circuit Breaker: Prevent cascade failures</li> </ul>"},{"location":"architecture-part-1/#event-driven-architecture","title":"\ud83d\udce1 Event-Driven Architecture","text":""},{"location":"architecture-part-1/#event-publishing-processing","title":"Event Publishing &amp; Processing","text":"<p>Our platform implements comprehensive event-driven patterns for monitoring, analytics, and system integration:</p>"},{"location":"architecture-part-1/#event-categories","title":"Event Categories:","text":""},{"location":"architecture-part-1/#business-events","title":"Business Events \ud83d\udcc8","text":"<ul> <li><code>PAN_SUBMITTED</code>: User submits PAN details</li> <li><code>PAN_OCR_PROCESSED</code>: OCR processing completed</li> <li><code>PAN_VERIFICATION_FAILED</code>: Verification failed</li> <li><code>LOAN_APPROVED</code>: Loan approval decision</li> <li><code>DOCUMENT_UPLOADED</code>: Document upload event</li> </ul>"},{"location":"architecture-part-1/#system-events","title":"System Events \u2699\ufe0f","text":"<ul> <li><code>PROVIDER_A_UNHEALTHY</code>: External service health</li> <li><code>WORKFLOW_TIMEOUT</code>: Process timeout events</li> <li><code>AUTHENTICATION_FAILED</code>: Security events</li> <li><code>RATE_LIMIT_EXCEEDED</code>: Usage monitoring</li> </ul>"},{"location":"architecture-part-1/#event-processing-pipeline","title":"Event Processing Pipeline","text":"<pre><code>flowchart LR\n    A[Event Generation] --&gt; B[Event Queue]\n    B --&gt; C[Event Consumer]\n    C --&gt; D[Event Storage]\n    D --&gt; E[Analytics Engine]\n    E --&gt; F[Dashboards &amp; Alerts]\n\n    C --&gt; G[Communication Service]\n    C --&gt; H[Alert System]\n\n    style A fill:#e1f5fe\n    style F fill:#e8f5e8\n    style G fill:#fff3e0\n    style H fill:#ffebee\n</code></pre>"},{"location":"architecture-part-1/#event-storage-analytics","title":"Event Storage &amp; Analytics:","text":"<ul> <li>Parquet Format: Efficient columnar storage</li> <li>S3 Integration: Scalable event data lake</li> <li>Columnar Queries: Fast aggregate analytics</li> <li>Real-time Alerts: Immediate notification system</li> </ul>"},{"location":"architecture-part-1/#monitoring-observability","title":"\ud83d\udd0d Monitoring &amp; Observability","text":""},{"location":"architecture-part-1/#comprehensive-logging-strategy","title":"Comprehensive Logging Strategy","text":""},{"location":"architecture-part-1/#production-debugging-philosophy","title":"Production Debugging Philosophy","text":"<p>\"Debugging in production is done purely by log checking\"</p> <p>Our logging strategy ensures complete observability:</p>"},{"location":"architecture-part-1/#request-lifecycle-logging","title":"Request Lifecycle Logging","text":"<ul> <li>Entry Point: Request received at NGINX</li> <li>Authentication: Token validation results</li> <li>State Validation: State machine decisions</li> <li>Workflow Execution: Temporal workflow progress</li> <li>External Calls: Third-party API interactions</li> <li>Response Generation: Final response preparation</li> </ul>"},{"location":"architecture-part-1/#log-levels-categories","title":"Log Levels &amp; Categories","text":"<pre><code>DEBUG: Detailed execution flow\nINFO:  Business process milestones\nWARN:  Recoverable issues\nERROR: System failures requiring attention\nFATAL: Critical system failures\n</code></pre>"},{"location":"architecture-part-1/#audit-trail-management","title":"Audit Trail Management","text":"<ul> <li>Access Logs: All API access patterns</li> <li>User Actions: Complete user journey tracking</li> <li>Agent Activities: Administrative action logging</li> <li>System Changes: Configuration and deployment logs</li> </ul>"},{"location":"architecture-part-1/#pitfalls-risk-management","title":"\u26a0\ufe0f Pitfalls &amp; Risk Management","text":""},{"location":"architecture-part-1/#common-pitfalls-mitigation-strategies","title":"Common Pitfalls &amp; Mitigation Strategies","text":""},{"location":"architecture-part-1/#1-queue-management-issues","title":"1. Queue Management Issues \ud83d\udea8","text":"<p>Pitfall: Message queue overflow during high traffic Mitigation: - Dead Letter Queue (DLQ): 5-minute TTL with offline analysis - Queue Monitoring: Real-time queue depth tracking - Auto-scaling: Dynamic worker scaling based on queue size - Circuit Breakers: Prevent cascade failures</p>"},{"location":"architecture-part-1/#2-workflow-timeout-handling","title":"2. Workflow Timeout Handling \u23f0","text":"<p>Pitfall: Long-running workflows causing resource exhaustion Mitigation: - Timeout Configuration: Per-workflow timeout settings - Progress Checkpoints: Regular state persistence - Resource Limits: Memory and CPU constraints - Graceful Degradation: Fallback processing paths</p>"},{"location":"architecture-part-1/#3-state-machine-inconsistencies","title":"3. State Machine Inconsistencies \ud83d\udd04","text":"<p>Pitfall: State drift between UI and backend Mitigation: - Single Source of Truth: Centralized state configuration - Validation Sync: Shared validation libraries - State Auditing: Complete state transition logging - Recovery Procedures: State correction mechanisms</p>"},{"location":"architecture-part-1/#4-authentication-token-issues","title":"4. Authentication Token Issues \ud83d\udd10","text":"<p>Pitfall: Token expiration and refresh failures Mitigation: - Graceful Token Refresh: Automatic background renewal - Token Validation Caching: Reduce SuperTokens load - Fallback Authentication: Multiple auth methods - Session Management: Proper session lifecycle handling</p>"},{"location":"architecture-part-1/#5-multi-tenant-data-isolation","title":"5. Multi-Tenant Data Isolation \ud83c\udfe2","text":"<p>Pitfall: Cross-tenant data leakage Mitigation: - Container Isolation: Dedicated tenant containers - Database Row-Level Security: Tenant-aware queries - Access Control: Strict authorization checks - Data Encryption: Tenant-specific encryption keys</p>"},{"location":"architecture-part-1/#monitoring-alerting-strategy","title":"\ud83d\udcca Monitoring &amp; Alerting Strategy","text":""},{"location":"architecture-part-1/#key-metrics-to-monitor","title":"Key Metrics to Monitor","text":""},{"location":"architecture-part-1/#performance-metrics","title":"Performance Metrics","text":"<ul> <li>Response Times: API endpoint latency</li> <li>Throughput: Requests per second</li> <li>Queue Depth: Message queue backlogs</li> <li>Workflow Duration: Process completion times</li> </ul>"},{"location":"architecture-part-1/#health-metrics","title":"Health Metrics","text":"<ul> <li>Container Health: CPU, memory, disk usage</li> <li>Database Performance: Query execution times</li> <li>External Service Health: Third-party API status</li> <li>Authentication Success Rate: Login failure patterns</li> </ul>"},{"location":"architecture-part-1/#business-metrics","title":"Business Metrics","text":"<ul> <li>User Journey Completion: Funnel analysis</li> <li>Error Rates: Business process failures</li> <li>Feature Usage: Plugin utilization patterns</li> <li>Client Activity: Tenant-specific metrics</li> </ul>"},{"location":"architecture-part-1/#alert-configuration","title":"Alert Configuration","text":""},{"location":"architecture-part-1/#critical-alerts","title":"Critical Alerts \ud83d\udea8","text":"<ul> <li>Authentication service down</li> <li>Database connection failures</li> <li>Workflow timeout exceeded</li> <li>Queue overflow conditions</li> </ul>"},{"location":"architecture-part-1/#warning-alerts","title":"Warning Alerts \u26a0\ufe0f","text":"<ul> <li>High response times</li> <li>Increased error rates</li> <li>Resource utilization spikes</li> <li>External service degradation</li> </ul>"},{"location":"architecture-part-1/#next-steps-future-enhancements","title":"\ud83c\udfaf Next Steps &amp; Future Enhancements","text":""},{"location":"architecture-part-1/#immediate-improvements","title":"Immediate Improvements","text":"<ol> <li>Metrics Dashboard: Real-time operational visibility</li> </ol>"},{"location":"architecture-part-1/#future-enhancements","title":"Future Enhancements","text":"<ol> <li>Caching Layer: Implement Redis for read-heavy operations</li> <li>Rate Limiting: Advanced rate limiting per tenant</li> <li>GraphQL Integration: Flexible query capabilities</li> <li>Event Sourcing: Complete event-driven architecture</li> <li>Multi-Region Deployment: Geographic distribution</li> <li>Advanced Analytics: ML-powered operational insights</li> <li>Automated Scaling: Container auto-scaling based on load</li> </ol>"},{"location":"architecture-part-2/","title":"Metis Platform Architecture - Part 2: Data Storage","text":"<p>Part 2 of 3: This document focuses on data storage architecture within the Metis platform. For complete context, refer to Introduction to Metis and Data Flow.</p>"},{"location":"architecture-part-2/#introduction","title":"\ud83d\udcbe Introduction","text":"<p>Data storage is the foundation of the Metis platform, providing reliable, scalable, and secure data persistence across our multi-tenant architecture. This document covers database design, storage patterns, backup strategies, and data management practices that ensure data integrity and optimal performance.</p> <p>Our storage architecture supports: - Multi-tenant data isolation - Scalable storage solutions - Comprehensive backup and recovery - Performance optimization</p>"},{"location":"architecture-part-2/#storage-architecture-overview","title":"\ud83c\udfd7\ufe0f Storage Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    METIS STORAGE ARCHITECTURE                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83d\uddc4\ufe0f PRIMARY STORAGE                                            \u2502\n\u2502  \u251c\u2500 PostgreSQL (Multi-tenant Database)                         \u2502\n\u2502  \u2514\u2500 Connection Pooling &amp; Query Optimization                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83d\udcc1 OBJECT STORAGE                                             \u2502\n\u2502  \u251c\u2500 S3 (Documents, Images, Files)                              \u2502\n\u2502  \u2514\u2500 MinIO (Development Environment)                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83d\udcca ANALYTICS STORAGE                                          \u2502\n\u2502  \u251c\u2500 ClickHouse (Event Analytics)                               \u2502\n\u2502  \u2514\u2500 DuckDB (Embedded Analytics)                                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83d\udd04 WORKFLOW STORAGE                                           \u2502\n\u2502  \u251c\u2500 Temporal Database                                          \u2502\n\u2502  \u2514\u2500 Workflow State Management                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \u26a1 CACHING LAYER                                              \u2502\n\u2502  \u251c\u2500 Redis (Session &amp; Query Cache)                              \u2502\n\u2502  \u2514\u2500 In-Memory Caching                                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture-part-2/#primary-database-postgresql","title":"\ud83d\uddc4\ufe0f Primary Database: PostgreSQL","text":""},{"location":"architecture-part-2/#multi-tenant-database-design","title":"Multi-Tenant Database Design","text":"<p>Our PostgreSQL implementation uses a shared database, shared schema approach with tenant isolation through row-level security:</p>"},{"location":"architecture-part-2/#database-schema-structure","title":"Database Schema Structure:","text":"<pre><code>-- Core tenant table\nCREATE TABLE tenants (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    name VARCHAR(255) NOT NULL,\n    subdomain VARCHAR(100) UNIQUE NOT NULL,\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW()\n);\n\n-- Example multi-tenant table\nCREATE TABLE users (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    tenant_id UUID NOT NULL REFERENCES tenants(id),\n    email VARCHAR(255) NOT NULL,\n    name VARCHAR(255) NOT NULL,\n    created_at TIMESTAMP DEFAULT NOW(),\n    UNIQUE(tenant_id, email)\n);\n\n-- Row Level Security\nALTER TABLE users ENABLE ROW LEVEL SECURITY;\nCREATE POLICY tenant_isolation ON users\n    USING (tenant_id = current_setting('app.current_tenant')::UUID);\n</code></pre>"},{"location":"architecture-part-2/#connection-management","title":"Connection Management","text":""},{"location":"architecture-part-2/#connection-pooling-configuration","title":"Connection Pooling Configuration:","text":"<pre><code>database:\n  host: localhost\n  port: 5432\n  name: metis_db\n  pool:\n    max_connections: 25\n    min_connections: 5\n    max_idle_time: 30m\n    max_lifetime: 1h\n</code></pre>"},{"location":"architecture-part-2/#query-optimization","title":"Query Optimization","text":""},{"location":"architecture-part-2/#indexing-strategy","title":"Indexing Strategy:","text":"<ul> <li>Tenant-aware indexes: All queries include tenant_id</li> <li>Composite indexes: Frequently queried column combinations</li> <li>Partial indexes: For conditional queries</li> <li>JSONB indexes: For flexible document storage</li> </ul> <pre><code>-- Tenant-aware composite index\nCREATE INDEX idx_users_tenant_email ON users(tenant_id, email);\n\n-- JSONB index for metadata\nCREATE INDEX idx_user_metadata ON users USING GIN(metadata);\n</code></pre>"},{"location":"architecture-part-2/#object-storage-s3-minio","title":"\ud83d\udcc1 Object Storage: S3 &amp; MinIO","text":""},{"location":"architecture-part-2/#storage-strategy","title":"Storage Strategy","text":""},{"location":"architecture-part-2/#file-organization","title":"File Organization:","text":"<pre><code>s3://metis-storage/\n\u251c\u2500\u2500 tenants/\n\u2502   \u251c\u2500\u2500 {tenant-id}/\n\u2502   \u2502   \u251c\u2500\u2500 documents/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 pan/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 aadhar/\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 bank-statements/\n\u2502   \u2502   \u251c\u2500\u2500 images/\n\u2502   \u2502   \u2514\u2500\u2500 reports/\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 ocr/\n\u2502   \u251c\u2500\u2500 risk-scoring/\n\u2502   \u2514\u2500\u2500 fraud-detection/\n\u2514\u2500\u2500 system/\n    \u251c\u2500\u2500 logs/\n    \u251c\u2500\u2500 backups/\n    \u2514\u2500\u2500 events/\n</code></pre>"},{"location":"architecture-part-2/#s3-configuration","title":"S3 Configuration","text":""},{"location":"architecture-part-2/#bucket-policies","title":"Bucket Policies:","text":"<pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\"AWS\": \"arn:aws:iam::account:role/MetisAppRole\"},\n      \"Action\": [\"s3:GetObject\", \"s3:PutObject\"],\n      \"Resource\": \"arn:aws:s3:::metis-storage/tenants/*\"\n    }\n  ]\n}\n</code></pre>"},{"location":"architecture-part-2/#lifecycle-management","title":"Lifecycle Management:","text":"<ul> <li>Standard: Active documents (0-30 days)</li> <li>IA: Archived documents (30-90 days)</li> <li>Glacier: Long-term storage (90+ days)</li> </ul>"},{"location":"architecture-part-2/#analytics-storage","title":"\ud83d\udcca Analytics Storage","text":""},{"location":"architecture-part-2/#clickhouse-for-event-analytics","title":"ClickHouse for Event Analytics","text":""},{"location":"architecture-part-2/#event-storage-schema","title":"Event Storage Schema:","text":"<pre><code>CREATE TABLE events (\n    event_id UUID,\n    tenant_id UUID,\n    event_type String,\n    event_data String,\n    user_id Nullable(UUID),\n    timestamp DateTime64(3),\n    created_date Date MATERIALIZED toDate(timestamp)\n) ENGINE = MergeTree()\nPARTITION BY created_date\nORDER BY (tenant_id, event_type, timestamp);\n</code></pre>"},{"location":"architecture-part-2/#query-patterns","title":"Query Patterns:","text":"<pre><code>-- Tenant-specific event analytics\nSELECT\n    event_type,\n    count() as event_count,\n    toStartOfHour(timestamp) as hour\nFROM events\nWHERE tenant_id = '...'\n    AND created_date &gt;= today() - 7\nGROUP BY event_type, hour\nORDER BY hour;\n</code></pre>"},{"location":"architecture-part-2/#duckdb-for-embedded-analytics","title":"DuckDB for Embedded Analytics","text":""},{"location":"architecture-part-2/#use-cases","title":"Use Cases:","text":"<ul> <li>Ad-hoc queries: Business intelligence queries</li> <li>Report generation: Scheduled reporting</li> <li>Data exploration: Interactive analysis</li> </ul> <pre><code>-- Combine S3 and local data\nSELECT\n    t.name as tenant_name,\n    count(*) as user_count\nFROM 's3://metis-storage/exports/users.parquet' u\nJOIN tenants t ON u.tenant_id = t.id\nGROUP BY t.name;\n</code></pre>"},{"location":"architecture-part-2/#workflow-storage-temporal","title":"\ud83d\udd04 Workflow Storage: Temporal","text":""},{"location":"architecture-part-2/#workflow-state-management","title":"Workflow State Management","text":""},{"location":"architecture-part-2/#temporal-database-schema","title":"Temporal Database Schema:","text":"<ul> <li>Workflow executions: Current and historical workflows</li> <li>Activity tasks: Individual workflow steps</li> <li>Timer tasks: Scheduled operations</li> <li>Visibility records: Workflow search and filtering</li> </ul>"},{"location":"architecture-part-2/#retention-policies","title":"Retention Policies:","text":"<pre><code>temporal:\n  retention:\n    workflow_execution_retention: 30d\n    visibility_archival: 7d\n    history_archival: 90d\n</code></pre>"},{"location":"architecture-part-2/#caching-strategy","title":"\u26a1 Caching Strategy","text":""},{"location":"architecture-part-2/#redis-implementation","title":"Redis Implementation","text":""},{"location":"architecture-part-2/#cache-patterns","title":"Cache Patterns:","text":"<pre><code>// Session caching\nfunc CacheUserSession(userID string, session *Session) error {\n    key := fmt.Sprintf(\"session:%s\", userID)\n    return redis.Set(key, session, 24*time.Hour)\n}\n\n// Query result caching\nfunc CacheQueryResult(query string, result interface{}) error {\n    key := fmt.Sprintf(\"query:%s\", hashQuery(query))\n    return redis.Set(key, result, 15*time.Minute)\n}\n</code></pre>"},{"location":"architecture-part-2/#cache-invalidation","title":"Cache Invalidation:","text":"<ul> <li>TTL-based: Automatic expiration</li> <li>Event-driven: Invalidate on data changes</li> <li>Manual: Explicit cache clearing</li> </ul>"},{"location":"architecture-part-2/#data-security-compliance","title":"\ud83d\udd12 Data Security &amp; Compliance","text":""},{"location":"architecture-part-2/#encryption","title":"Encryption","text":""},{"location":"architecture-part-2/#at-rest","title":"At Rest:","text":"<ul> <li>Database: PostgreSQL TDE (Transparent Data Encryption)</li> <li>S3: Server-side encryption with KMS</li> <li>Backups: Encrypted backup storage</li> </ul>"},{"location":"architecture-part-2/#in-transit","title":"In Transit:","text":"<ul> <li>TLS 1.3: All database connections</li> <li>HTTPS: All API communications</li> <li>VPN: Internal service communication</li> </ul>"},{"location":"architecture-part-2/#data-privacy","title":"Data Privacy","text":""},{"location":"architecture-part-2/#gdpr-compliance","title":"GDPR Compliance:","text":"<ul> <li>Data minimization: Store only necessary data</li> <li>Right to erasure: Automated data deletion</li> <li>Data portability: Export capabilities</li> <li>Audit trails: Complete access logging</li> </ul>"},{"location":"architecture-part-2/#backup-recovery","title":"\ud83d\udcbe Backup &amp; Recovery","text":""},{"location":"architecture-part-2/#backup-strategy","title":"Backup Strategy","text":"<pre><code>flowchart TD\n    A[Continuous WAL Backup] --&gt; B[Point-in-Time Recovery]\n    C[Daily Full Backup] --&gt; D[Weekly Archive]\n    E[S3 Versioning] --&gt; F[Cross-Region Replication]\n    G[Event Stream Backup] --&gt; H[Analytics Recovery]\n\n    style A fill:#e1f5fe\n    style C fill:#e8f5e8\n    style E fill:#fff3e0\n    style G fill:#f3e5f5\n</code></pre>"},{"location":"architecture-part-2/#backup-schedule","title":"Backup Schedule:","text":"<ul> <li>Continuous: WAL (Write-Ahead Log) streaming</li> <li>Daily: Full database backup</li> <li>Weekly: Archive to long-term storage</li> <li>Monthly: Disaster recovery testing</li> </ul>"},{"location":"architecture-part-2/#recovery-procedures","title":"Recovery Procedures","text":""},{"location":"architecture-part-2/#rtorpo-targets","title":"RTO/RPO Targets:","text":"<ul> <li>RTO (Recovery Time Objective): 4 hours</li> <li>RPO (Recovery Point Objective): 15 minutes</li> <li>Data Loss Tolerance: &lt; 1 hour</li> </ul>"},{"location":"architecture-part-2/#performance-optimization","title":"\ud83d\udcc8 Performance Optimization","text":""},{"location":"architecture-part-2/#database-performance","title":"Database Performance","text":""},{"location":"architecture-part-2/#query-optimization_1","title":"Query Optimization:","text":"<pre><code>-- Efficient tenant-aware queries\nEXPLAIN (ANALYZE, BUFFERS)\nSELECT * FROM users\nWHERE tenant_id = $1 AND email = $2;\n\n-- Index usage verification\nSELECT schemaname, tablename, indexname, idx_scan, idx_tup_read\nFROM pg_stat_user_indexes\nWHERE idx_scan &gt; 0;\n</code></pre>"},{"location":"architecture-part-2/#connection-pooling","title":"Connection Pooling:","text":"<ul> <li>PgBouncer: Connection pooling middleware</li> <li>Pool sizing: Based on concurrent users</li> <li>Connection limits: Prevent database overload</li> </ul>"},{"location":"architecture-part-2/#storage-performance","title":"Storage Performance","text":""},{"location":"architecture-part-2/#s3-optimization","title":"S3 Optimization:","text":"<ul> <li>Multipart uploads: Large file handling</li> <li>Transfer acceleration: Global content delivery</li> <li>Request patterns: Optimize for access patterns</li> </ul>"},{"location":"architecture-part-2/#monitoring-alerting","title":"\ud83d\udd0d Monitoring &amp; Alerting","text":""},{"location":"architecture-part-2/#database-monitoring","title":"Database Monitoring","text":""},{"location":"architecture-part-2/#key-metrics","title":"Key Metrics:","text":"<ul> <li>Connection count: Active/idle connections</li> <li>Query performance: Slow query identification</li> <li>Lock contention: Blocking queries</li> <li>Replication lag: Backup synchronization</li> </ul>"},{"location":"architecture-part-2/#alerts","title":"Alerts:","text":"<pre><code>alerts:\n  - name: high_connection_count\n    condition: connections &gt; 80% of max\n    severity: warning\n\n  - name: slow_queries\n    condition: query_time &gt; 5s\n    severity: critical\n\n  - name: disk_space\n    condition: disk_usage &gt; 85%\n    severity: warning\n</code></pre>"},{"location":"architecture-part-2/#storage-monitoring","title":"Storage Monitoring","text":""},{"location":"architecture-part-2/#s3-metrics","title":"S3 Metrics:","text":"<ul> <li>Storage utilization: Bucket size growth</li> <li>Request patterns: GET/PUT request rates</li> <li>Error rates: Failed operations</li> <li>Cost tracking: Storage and transfer costs</li> </ul>"},{"location":"architecture-part-2/#common-pitfalls-solutions","title":"\u26a0\ufe0f Common Pitfalls &amp; Solutions","text":""},{"location":"architecture-part-2/#1-connection-pool-exhaustion","title":"1. Connection Pool Exhaustion \ud83d\udea8","text":"<p>Problem: Too many concurrent connections Solution: - Implement connection pooling - Set appropriate pool sizes - Monitor connection usage - Use read replicas for read-heavy workloads</p>"},{"location":"architecture-part-2/#2-tenant-data-leakage","title":"2. Tenant Data Leakage \ud83d\udd12","text":"<p>Problem: Cross-tenant data access Solution: - Row-level security policies - Application-level tenant validation - Regular security audits - Automated testing for data isolation</p>"},{"location":"architecture-part-2/#3-storage-cost-explosion","title":"3. Storage Cost Explosion \ud83d\udcb0","text":"<p>Problem: Uncontrolled storage growth Solution: - Implement lifecycle policies - Regular data archival - Compression strategies - Cost monitoring and alerts</p>"},{"location":"architecture-part-2/#4-backup-failures","title":"4. Backup Failures \ud83d\udcbe","text":"<p>Problem: Backup corruption or failure Solution: - Regular backup testing - Multiple backup strategies - Automated backup verification - Cross-region backup replication</p>"},{"location":"architecture-part-2/#future-enhancements","title":"\ud83c\udfaf Future Enhancements","text":""},{"location":"architecture-part-2/#immediate-improvements","title":"Immediate Improvements","text":"<ol> <li>Read Replicas: Implement for read scaling</li> <li>Partitioning: Table partitioning for large datasets</li> <li>Compression: Database and storage compression</li> </ol>"},{"location":"architecture-part-2/#future-enhancements_1","title":"Future Enhancements","text":"<ol> <li>Sharding: Horizontal database scaling</li> <li>Multi-Region: Geographic data distribution</li> <li>Data Lake: Advanced analytics infrastructure</li> <li>Real-time Sync: Event-driven data synchronization</li> </ol> <p>This document provides the foundation for understanding data storage within the Metis platform. Next: Data Processing covers ML pipelines and business logic processing.</p>"},{"location":"architecture-part-3/","title":"Metis Platform Architecture - Part 3: Data Processing","text":"<p>Part 3 of 3: This document focuses on data processing architecture within the Metis platform. For complete context, refer to Introduction to Metis, Data Flow, and Data Storage.</p>"},{"location":"architecture-part-3/#introduction","title":"\u2699\ufe0f Introduction","text":"<p>Data processing is the intelligence layer of the Metis platform, transforming raw data into actionable insights through machine learning models, business logic, and workflow orchestration. This document covers ML pipelines, processing patterns, and orchestration strategies that power our platform's decision-making capabilities.</p> <p>Our processing architecture enables: - Real-time ML inference - Complex workflow orchestration - Scalable business logic processing - Event-driven data transformation</p>"},{"location":"architecture-part-3/#processing-architecture-overview","title":"\ud83c\udfd7\ufe0f Processing Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   METIS PROCESSING ARCHITECTURE                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83e\udde0 ML PROCESSING LAYER                                        \u2502\n\u2502  \u251c\u2500 FastAPI ML Server (Python)                                 \u2502\n\u2502  \u251c\u2500 Common Models (OCR, Classification)                        \u2502\n\u2502  \u2514\u2500 Client-Specific Models (Risk, Fraud)                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83d\udd04 WORKFLOW ORCHESTRATION                                     \u2502\n\u2502  \u251c\u2500 Temporal Workflows                                         \u2502\n\u2502  \u251c\u2500 Business Process Management                                \u2502\n\u2502  \u2514\u2500 State Machine Coordination                                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \u26a1 BUSINESS LOGIC PROCESSING                                  \u2502\n\u2502  \u251c\u2500 Core App Services (Go)                                     \u2502\n\u2502  \u251c\u2500 Rules Engine                                               \u2502\n\u2502  \u2514\u2500 Decision Making Logic                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83d\udcca EVENT PROCESSING                                           \u2502\n\u2502  \u251c\u2500 Event Consumers                                            \u2502\n\u2502  \u251c\u2500 Stream Processing                                          \u2502\n\u2502  \u2514\u2500 Analytics Pipeline                                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83d\udd17 EXTERNAL INTEGRATIONS                                      \u2502\n\u2502  \u251c\u2500 Third-party APIs                                           \u2502\n\u2502  \u251c\u2500 Bureau Services                                            \u2502\n\u2502  \u2514\u2500 Notification Services                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture-part-3/#ml-processing-layer","title":"\ud83e\udde0 ML Processing Layer","text":""},{"location":"architecture-part-3/#fastapi-ml-server-architecture","title":"FastAPI ML Server Architecture","text":"<p>Our ML processing is handled by a dedicated Python FastAPI server that provides scalable model inference:</p>"},{"location":"architecture-part-3/#server-structure","title":"Server Structure:","text":"<pre><code># cmd/ml/main.py\nfrom fastapi import FastAPI, HTTPException\nfrom pylibs.models import OCRModel, RiskModel\nfrom pylibs.preprocessing import DocumentProcessor\n\napp = FastAPI(title=\"Metis ML API\", version=\"1.0.0\")\n\n# Model initialization\nocr_model = OCRModel()\nrisk_model = RiskModel()\nprocessor = DocumentProcessor()\n\n@app.post(\"/ocr/process\")\nasync def process_document(file: UploadFile):\n    \"\"\"Process document through OCR pipeline\"\"\"\n    processed_data = await processor.preprocess(file)\n    result = ocr_model.predict(processed_data)\n    return {\"extracted_data\": result}\n\n@app.post(\"/risk/score\")\nasync def calculate_risk_score(data: RiskInput):\n    \"\"\"Calculate risk score for given input\"\"\"\n    features = processor.extract_features(data)\n    score = risk_model.predict(features)\n    return {\"risk_score\": score, \"confidence\": score.confidence}\n</code></pre>"},{"location":"architecture-part-3/#model-categories","title":"Model Categories","text":""},{"location":"architecture-part-3/#1-common-models","title":"1. Common Models \ud83d\udd04","text":"<p>OCR Engine:</p> <pre><code>class OCRModel:\n    def __init__(self):\n        self.model = load_pretrained_ocr_model()\n\n    def extract_text(self, image_data):\n        \"\"\"Extract text from document images\"\"\"\n        preprocessed = self.preprocess_image(image_data)\n        text_data = self.model.predict(preprocessed)\n        return self.postprocess_text(text_data)\n\n    def extract_fields(self, document_type, text_data):\n        \"\"\"Extract specific fields based on document type\"\"\"\n        field_extractor = self.get_field_extractor(document_type)\n        return field_extractor.extract(text_data)\n</code></pre> <p>Document Classification:</p> <pre><code>class DocumentClassifier:\n    def classify_document(self, image_data):\n        \"\"\"Classify document type (PAN, Aadhar, Bank Statement)\"\"\"\n        features = self.extract_visual_features(image_data)\n        document_type = self.classifier.predict(features)\n        confidence = self.classifier.predict_proba(features)\n        return {\n            \"document_type\": document_type,\n            \"confidence\": confidence,\n            \"processing_pipeline\": self.get_pipeline(document_type)\n        }\n</code></pre>"},{"location":"architecture-part-3/#2-client-specific-models","title":"2. Client-Specific Models \ud83c\udfaf","text":"<p>Risk Scoring Models:</p> <pre><code>class ClientRiskModel:\n    def __init__(self, client_id):\n        self.client_id = client_id\n        self.model = self.load_client_model(client_id)\n        self.features = self.load_feature_config(client_id)\n\n    def calculate_risk_score(self, applicant_data):\n        \"\"\"Calculate client-specific risk score\"\"\"\n        features = self.extract_features(applicant_data)\n        risk_score = self.model.predict(features)\n\n        return {\n            \"risk_score\": risk_score,\n            \"risk_category\": self.categorize_risk(risk_score),\n            \"contributing_factors\": self.explain_prediction(features),\n            \"model_version\": self.model.version\n        }\n</code></pre>"},{"location":"architecture-part-3/#model-deployment-versioning","title":"Model Deployment &amp; Versioning","text":""},{"location":"architecture-part-3/#model-registry","title":"Model Registry:","text":"<pre><code>class ModelRegistry:\n    def __init__(self):\n        self.models = {}\n        self.versions = {}\n\n    def register_model(self, model_name, model_version, model_path):\n        \"\"\"Register new model version\"\"\"\n        model_key = f\"{model_name}:{model_version}\"\n        self.models[model_key] = self.load_model(model_path)\n        self.versions[model_name] = model_version\n\n    def get_model(self, model_name, version=None):\n        \"\"\"Get model by name and version\"\"\"\n        if version is None:\n            version = self.versions[model_name]\n        return self.models[f\"{model_name}:{version}\"]\n</code></pre>"},{"location":"architecture-part-3/#workflow-orchestration-with-temporal","title":"\ud83d\udd04 Workflow Orchestration with Temporal","text":""},{"location":"architecture-part-3/#workflow-architecture","title":"Workflow Architecture","text":"<p>Our platform uses Temporal for complex business process orchestration:</p>"},{"location":"architecture-part-3/#workflow-definition","title":"Workflow Definition:","text":"<pre><code>// pkg/workflows/loan_processing.go\nfunc LoanProcessingWorkflow(ctx workflow.Context, input LoanApplication) error {\n    logger := workflow.GetLogger(ctx)\n\n    // Step 1: Document Processing\n    var docResult DocumentProcessingResult\n    err := workflow.ExecuteActivity(ctx, ProcessDocumentsActivity, input.Documents).Get(ctx, &amp;docResult)\n    if err != nil {\n        return fmt.Errorf(\"document processing failed: %w\", err)\n    }\n\n    // Step 2: Bureau Data Pull\n    var bureauResult BureauDataResult\n    err = workflow.ExecuteActivity(ctx, PullBureauDataActivity, input.ApplicantID).Get(ctx, &amp;bureauResult)\n    if err != nil {\n        return fmt.Errorf(\"bureau data pull failed: %w\", err)\n    }\n\n    // Step 3: Risk Assessment\n    riskInput := RiskAssessmentInput{\n        Documents: docResult,\n        BureauData: bureauResult,\n        Application: input,\n    }\n\n    var riskResult RiskAssessmentResult\n    err = workflow.ExecuteActivity(ctx, RiskAssessmentActivity, riskInput).Get(ctx, &amp;riskResult)\n    if err != nil {\n        return fmt.Errorf(\"risk assessment failed: %w\", err)\n    }\n\n    // Step 4: Decision Making\n    decision := makeDecision(riskResult)\n\n    // Step 5: Notification\n    return workflow.ExecuteActivity(ctx, NotifyApplicantActivity, decision).Get(ctx, nil)\n}\n</code></pre>"},{"location":"architecture-part-3/#activity-implementation","title":"Activity Implementation:","text":"<pre><code>func ProcessDocumentsActivity(ctx context.Context, documents []Document) (DocumentProcessingResult, error) {\n    var result DocumentProcessingResult\n\n    for _, doc := range documents {\n        // Call ML service for OCR processing\n        ocrResult, err := callMLService(\"/ocr/process\", doc)\n        if err != nil {\n            return result, fmt.Errorf(\"OCR processing failed: %w\", err)\n        }\n\n        // Validate extracted data\n        validationResult := validateExtractedData(ocrResult)\n\n        result.ProcessedDocuments = append(result.ProcessedDocuments, ProcessedDocument{\n            OriginalDocument: doc,\n            ExtractedData:    ocrResult,\n            ValidationResult: validationResult,\n        })\n    }\n\n    return result, nil\n}\n</code></pre>"},{"location":"architecture-part-3/#workflow-patterns","title":"Workflow Patterns","text":""},{"location":"architecture-part-3/#1-sequential-processing","title":"1. Sequential Processing:","text":"<pre><code>// Linear workflow for simple processes\nfunc SimpleApprovalWorkflow(ctx workflow.Context, application Application) error {\n    // Step 1 -&gt; Step 2 -&gt; Step 3 -&gt; Decision\n    return executeSequentialSteps(ctx, application)\n}\n</code></pre>"},{"location":"architecture-part-3/#2-parallel-processing","title":"2. Parallel Processing:","text":"<pre><code>// Parallel execution for independent tasks\nfunc ParallelProcessingWorkflow(ctx workflow.Context, application Application) error {\n    // Execute multiple activities in parallel\n    futures := []workflow.Future{\n        workflow.ExecuteActivity(ctx, ProcessDocuments, application.Documents),\n        workflow.ExecuteActivity(ctx, PullBureauData, application.ApplicantID),\n        workflow.ExecuteActivity(ctx, ValidateApplication, application),\n    }\n\n    // Wait for all to complete\n    for _, future := range futures {\n        if err := future.Get(ctx, nil); err != nil {\n            return err\n        }\n    }\n\n    return nil\n}\n</code></pre>"},{"location":"architecture-part-3/#3-conditional-workflows","title":"3. Conditional Workflows:","text":"<pre><code>// Conditional execution based on business rules\nfunc ConditionalWorkflow(ctx workflow.Context, application Application) error {\n    if application.Amount &gt; 1000000 {\n        return executeHighValueWorkflow(ctx, application)\n    }\n    return executeStandardWorkflow(ctx, application)\n}\n</code></pre>"},{"location":"architecture-part-3/#business-logic-processing","title":"\u26a1 Business Logic Processing","text":""},{"location":"architecture-part-3/#rules-engine-architecture","title":"Rules Engine Architecture","text":"<p>Our rules engine provides flexible, configurable business logic:</p>"},{"location":"architecture-part-3/#rule-definition","title":"Rule Definition:","text":"<pre><code>type Rule struct {\n    ID          string                 `json:\"id\"`\n    Name        string                 `json:\"name\"`\n    Conditions  []Condition            `json:\"conditions\"`\n    Actions     []Action               `json:\"actions\"`\n    Priority    int                    `json:\"priority\"`\n    TenantID    string                 `json:\"tenant_id\"`\n}\n\ntype Condition struct {\n    Field    string      `json:\"field\"`\n    Operator string      `json:\"operator\"`\n    Value    interface{} `json:\"value\"`\n}\n\ntype Action struct {\n    Type   string                 `json:\"type\"`\n    Params map[string]interface{} `json:\"params\"`\n}\n</code></pre>"},{"location":"architecture-part-3/#rules-engine-implementation","title":"Rules Engine Implementation:","text":"<pre><code>type RulesEngine struct {\n    rules []Rule\n}\n\nfunc (re *RulesEngine) EvaluateRules(data map[string]interface{}) ([]Action, error) {\n    var actions []Action\n\n    // Sort rules by priority\n    sort.Slice(re.rules, func(i, j int) bool {\n        return re.rules[i].Priority &gt; re.rules[j].Priority\n    })\n\n    for _, rule := range re.rules {\n        if re.evaluateConditions(rule.Conditions, data) {\n            actions = append(actions, rule.Actions...)\n        }\n    }\n\n    return actions, nil\n}\n\nfunc (re *RulesEngine) evaluateConditions(conditions []Condition, data map[string]interface{}) bool {\n    for _, condition := range conditions {\n        if !re.evaluateCondition(condition, data) {\n            return false\n        }\n    }\n    return true\n}\n</code></pre>"},{"location":"architecture-part-3/#decision-making-logic","title":"Decision Making Logic","text":""},{"location":"architecture-part-3/#credit-decision-engine","title":"Credit Decision Engine:","text":"<pre><code>type CreditDecisionEngine struct {\n    rulesEngine *RulesEngine\n    riskModel   *RiskModel\n}\n\nfunc (cde *CreditDecisionEngine) MakeDecision(application LoanApplication, riskScore float64) Decision {\n    // Combine rule-based and ML-based decisions\n    ruleDecision := cde.evaluateRules(application, riskScore)\n    mlDecision := cde.evaluateMLModel(application, riskScore)\n\n    // Final decision logic\n    finalDecision := cde.combineDecisions(ruleDecision, mlDecision)\n\n    return Decision{\n        Outcome:     finalDecision.Outcome,\n        Confidence:  finalDecision.Confidence,\n        Reasons:     finalDecision.Reasons,\n        Conditions:  finalDecision.Conditions,\n        Timestamp:   time.Now(),\n    }\n}\n</code></pre>"},{"location":"architecture-part-3/#event-processing-pipeline","title":"\ud83d\udcca Event Processing Pipeline","text":""},{"location":"architecture-part-3/#event-driven-architecture","title":"Event-Driven Architecture","text":"<p>Our platform processes events in real-time for analytics and monitoring:</p>"},{"location":"architecture-part-3/#event-consumer","title":"Event Consumer:","text":"<pre><code>type EventConsumer struct {\n    queue      *rabbitmq.Queue\n    processor  *EventProcessor\n    clickhouse *clickhouse.Client\n}\n\nfunc (ec *EventConsumer) ProcessEvents() error {\n    return ec.queue.Consume(func(event Event) error {\n        // Process event\n        processedEvent := ec.processor.Process(event)\n\n        // Store in analytics database\n        return ec.clickhouse.Insert(\"events\", processedEvent)\n    })\n}\n</code></pre>"},{"location":"architecture-part-3/#stream-processing","title":"Stream Processing:","text":"<pre><code>type StreamProcessor struct {\n    inputStream  chan Event\n    outputStream chan ProcessedEvent\n}\n\nfunc (sp *StreamProcessor) ProcessStream() {\n    for event := range sp.inputStream {\n        // Real-time event processing\n        processedEvent := sp.processEvent(event)\n\n        // Trigger alerts if needed\n        if sp.shouldAlert(processedEvent) {\n            sp.triggerAlert(processedEvent)\n        }\n\n        sp.outputStream &lt;- processedEvent\n    }\n}\n</code></pre>"},{"location":"architecture-part-3/#external-integrations","title":"\ud83d\udd17 External Integrations","text":""},{"location":"architecture-part-3/#third-party-api-integration","title":"Third-Party API Integration","text":""},{"location":"architecture-part-3/#bureau-integration","title":"Bureau Integration:","text":"<pre><code>type BureauClient struct {\n    httpClient *http.Client\n    config     BureauConfig\n}\n\nfunc (bc *BureauClient) PullCreditReport(applicantID string) (*CreditReport, error) {\n    // Implement retry logic with exponential backoff\n    return retry.Do(func() (*CreditReport, error) {\n        request := bc.buildRequest(applicantID)\n        response, err := bc.httpClient.Do(request)\n        if err != nil {\n            return nil, err\n        }\n\n        return bc.parseResponse(response)\n    }, retry.Attempts(3), retry.Delay(time.Second))\n}\n</code></pre>"},{"location":"architecture-part-3/#notification-service","title":"Notification Service:","text":"<pre><code>type NotificationService struct {\n    emailClient *email.Client\n    smsClient   *sms.Client\n}\n\nfunc (ns *NotificationService) SendDecisionNotification(applicant Applicant, decision Decision) error {\n    // Send email notification\n    emailErr := ns.emailClient.Send(email.Message{\n        To:      applicant.Email,\n        Subject: \"Loan Application Decision\",\n        Body:    ns.buildEmailBody(decision),\n    })\n\n    // Send SMS notification\n    smsErr := ns.smsClient.Send(sms.Message{\n        To:   applicant.Phone,\n        Body: ns.buildSMSBody(decision),\n    })\n\n    // Return combined errors\n    return errors.Join(emailErr, smsErr)\n}\n</code></pre>"},{"location":"architecture-part-3/#performance-optimization","title":"\ud83d\udcc8 Performance Optimization","text":""},{"location":"architecture-part-3/#processing-performance","title":"Processing Performance","text":""},{"location":"architecture-part-3/#async-processing","title":"Async Processing:","text":"<pre><code>type AsyncProcessor struct {\n    workerPool chan struct{}\n    taskQueue  chan Task\n}\n\nfunc (ap *AsyncProcessor) ProcessAsync(task Task) {\n    select {\n    case ap.taskQueue &lt;- task:\n        // Task queued successfully\n    default:\n        // Queue full, handle overflow\n        ap.handleOverflow(task)\n    }\n}\n\nfunc (ap *AsyncProcessor) worker() {\n    for {\n        select {\n        case &lt;-ap.workerPool:\n            task := &lt;-ap.taskQueue\n            ap.processTask(task)\n            ap.workerPool &lt;- struct{}{} // Return worker to pool\n        }\n    }\n}\n</code></pre>"},{"location":"architecture-part-3/#caching-strategy","title":"Caching Strategy:","text":"<pre><code>type ProcessingCache struct {\n    cache *redis.Client\n    ttl   time.Duration\n}\n\nfunc (pc *ProcessingCache) GetOrProcess(key string, processor func() (interface{}, error)) (interface{}, error) {\n    // Try cache first\n    if result, err := pc.cache.Get(key).Result(); err == nil {\n        return result, nil\n    }\n\n    // Process and cache result\n    result, err := processor()\n    if err != nil {\n        return nil, err\n    }\n\n    pc.cache.Set(key, result, pc.ttl)\n    return result, nil\n}\n</code></pre>"},{"location":"architecture-part-3/#monitoring-observability","title":"\ud83d\udd0d Monitoring &amp; Observability","text":""},{"location":"architecture-part-3/#processing-metrics","title":"Processing Metrics","text":""},{"location":"architecture-part-3/#key-metrics","title":"Key Metrics:","text":"<pre><code>var (\n    processingDuration = prometheus.NewHistogramVec(\n        prometheus.HistogramOpts{\n            Name: \"processing_duration_seconds\",\n            Help: \"Duration of processing operations\",\n        },\n        []string{\"operation\", \"tenant\"},\n    )\n\n    processingErrors = prometheus.NewCounterVec(\n        prometheus.CounterOpts{\n            Name: \"processing_errors_total\",\n            Help: \"Total number of processing errors\",\n        },\n        []string{\"operation\", \"error_type\"},\n    )\n)\n</code></pre>"},{"location":"architecture-part-3/#workflow-monitoring","title":"Workflow Monitoring:","text":"<pre><code>func MonitorWorkflow(ctx workflow.Context, workflowName string) {\n    workflow.GetMetricsScope(ctx).Counter(\"workflow_started\").Inc(1)\n\n    defer func() {\n        if workflow.IsReplaying(ctx) {\n            return\n        }\n        workflow.GetMetricsScope(ctx).Counter(\"workflow_completed\").Inc(1)\n    }()\n}\n</code></pre>"},{"location":"architecture-part-3/#common-pitfalls-solutions","title":"\u26a0\ufe0f Common Pitfalls &amp; Solutions","text":""},{"location":"architecture-part-3/#1-ml-model-performance-degradation","title":"1. ML Model Performance Degradation \ud83e\udde0","text":"<p>Problem: Model accuracy decreases over time Solution: - Implement model monitoring - Regular model retraining - A/B testing for model versions - Performance drift detection</p>"},{"location":"architecture-part-3/#2-workflow-timeout-issues","title":"2. Workflow Timeout Issues \u23f0","text":"<p>Problem: Long-running workflows timing out Solution: - Implement heartbeat activities - Break workflows into smaller chunks - Use continue-as-new pattern - Proper timeout configuration</p>"},{"location":"architecture-part-3/#3-external-api-failures","title":"3. External API Failures \ud83d\udd17","text":"<p>Problem: Third-party service unavailability Solution: - Implement circuit breakers - Retry with exponential backoff - Fallback mechanisms - Service health monitoring</p>"},{"location":"architecture-part-3/#4-processing-bottlenecks","title":"4. Processing Bottlenecks \u26a1","text":"<p>Problem: Processing queue backlog Solution: - Horizontal scaling of workers - Load balancing strategies - Queue monitoring and alerting - Resource optimization</p>"},{"location":"architecture-part-3/#future-enhancements","title":"\ud83c\udfaf Future Enhancements","text":""},{"location":"architecture-part-3/#immediate-improvements","title":"Immediate Improvements","text":"<ol> <li>Model Serving: Implement model serving infrastructure</li> <li>Batch Processing: Add batch processing capabilities</li> <li>Real-time Analytics: Stream processing for real-time insights</li> </ol>"},{"location":"architecture-part-3/#future-enhancements_1","title":"Future Enhancements","text":"<ol> <li>AutoML: Automated model training and deployment</li> <li>Edge Computing: Edge-based model inference</li> <li>Federated Learning: Privacy-preserving model training</li> <li>Advanced Orchestration: Complex workflow patterns</li> </ol> <p>This completes the three-part architecture series. Together with Introduction to Metis, Data Flow, and Data Storage, this provides a comprehensive view of the Metis platform architecture.</p>"},{"location":"deployment-guide/","title":"Deployment Guide","text":"<p>Comprehensive deployment guide for the Metis platform covering local development, staging, and production environments.</p>"},{"location":"deployment-guide/#overview","title":"\ud83d\udccb Overview","text":"<p>This guide covers the complete deployment strategy for the Metis platform, from local development setup to production deployment. The platform uses a containerized microservices architecture with Kubernetes orchestration.</p> <p>Deployment Environments: - Local Development: Docker Compose for rapid development - Staging: Kubernetes cluster for testing and validation - Production: Multi-region Kubernetes deployment with high availability</p>"},{"location":"deployment-guide/#infrastructure-architecture","title":"\ud83c\udfd7\ufe0f Infrastructure Architecture","text":""},{"location":"deployment-guide/#deployment-topology","title":"Deployment Topology","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    PRODUCTION DEPLOYMENT                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83c\udf10 LOAD BALANCER (AWS ALB)                                   \u2502\n\u2502  \u251c\u2500 SSL Termination                                            \u2502\n\u2502  \u251c\u2500 Health Checks                                              \u2502\n\u2502  \u2514\u2500 Traffic Distribution                                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \u2638\ufe0f KUBERNETES CLUSTER (EKS)                                  \u2502\n\u2502  \u251c\u2500 Core App Services (Go)                                     \u2502\n\u2502  \u251c\u2500 ML Services (Python/FastAPI)                               \u2502\n\u2502  \u251c\u2500 Temporal Workers                                           \u2502\n\u2502  \u2514\u2500 Supporting Services                                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83d\udcbe DATA LAYER                                                \u2502\n\u2502  \u251c\u2500 RDS PostgreSQL (Multi-AZ)                                  \u2502\n\u2502  \u251c\u2500 ElastiCache Redis (Cluster Mode)                           \u2502\n\u2502  \u251c\u2500 S3 (Multi-region replication)                              \u2502\n\u2502  \u2514\u2500 RabbitMQ (Clustered)                                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83d\udcca MONITORING &amp; LOGGING                                      \u2502\n\u2502  \u251c\u2500 Prometheus + Grafana                                       \u2502\n\u2502  \u251c\u2500 ELK Stack (Elasticsearch, Logstash, Kibana)               \u2502\n\u2502  \u2514\u2500 AWS CloudWatch                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"deployment-guide/#local-development-setup","title":"\ud83d\udc33 Local Development Setup","text":""},{"location":"deployment-guide/#prerequisites","title":"Prerequisites","text":"<pre><code># Required tools\n- Docker Desktop 4.20+\n- Docker Compose 2.20+\n- Go 1.21+\n- Python 3.11+\n- Node.js 18+ (for frontend)\n- kubectl 1.28+\n- Helm 3.12+\n</code></pre>"},{"location":"deployment-guide/#environment-setup","title":"Environment Setup","text":"<pre><code># Clone repository\ngit clone https://github.com/metis/platform.git\ncd platform\n\n# Copy environment template\ncp .env.example .env.local\n\n# Edit environment variables\nvim .env.local\n</code></pre>"},{"location":"deployment-guide/#environment-variables","title":"Environment Variables","text":"<pre><code># .env.local\n# Database Configuration\nPOSTGRES_HOST=localhost\nPOSTGRES_PORT=5432\nPOSTGRES_DB=metis_dev\nPOSTGRES_USER=metis\nPOSTGRES_PASSWORD=dev_password\n\n# Redis Configuration\nREDIS_HOST=localhost\nREDIS_PORT=6379\nREDIS_PASSWORD=\n\n# S3 Configuration (LocalStack)\nAWS_ENDPOINT_URL=http://localhost:4566\nAWS_ACCESS_KEY_ID=test\nAWS_SECRET_ACCESS_KEY=test\nAWS_REGION=us-east-1\nS3_BUCKET=metis-dev-bucket\n\n# RabbitMQ Configuration\nRABBITMQ_HOST=localhost\nRABBITMQ_PORT=5672\nRABBITMQ_USER=metis\nRABBITMQ_PASSWORD=dev_password\n\n# Temporal Configuration\nTEMPORAL_HOST=localhost\nTEMPORAL_PORT=7233\n\n# ML Service Configuration\nML_SERVICE_URL=http://localhost:8001\nMODEL_STORAGE_PATH=/app/models\n\n# Application Configuration\nAPP_ENV=development\nLOG_LEVEL=debug\nJWT_SECRET=dev_jwt_secret_key\nENCRYPTION_KEY=dev_encryption_key_32_chars\n</code></pre>"},{"location":"deployment-guide/#docker-compose-setup","title":"Docker Compose Setup","text":"<pre><code># docker-compose.dev.yml\nversion: '3.8'\n\nservices:\n  # Database\n  postgres:\n    image: postgres:15\n    environment:\n      POSTGRES_DB: metis_dev\n      POSTGRES_USER: metis\n      POSTGRES_PASSWORD: dev_password\n    ports:\n      - \"5432:5432\"\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init.sql\n\n  # Redis Cache\n  redis:\n    image: redis:7-alpine\n    ports:\n      - \"6379:6379\"\n    volumes:\n      - redis_data:/data\n\n  # LocalStack (AWS Services)\n  localstack:\n    image: localstack/localstack:latest\n    environment:\n      SERVICES: s3,sqs,sns\n      DEBUG: 1\n      DATA_DIR: /tmp/localstack/data\n    ports:\n      - \"4566:4566\"\n    volumes:\n      - localstack_data:/tmp/localstack\n\n  # RabbitMQ\n  rabbitmq:\n    image: rabbitmq:3-management\n    environment:\n      RABBITMQ_DEFAULT_USER: metis\n      RABBITMQ_DEFAULT_PASS: dev_password\n    ports:\n      - \"5672:5672\"\n      - \"15672:15672\"\n    volumes:\n      - rabbitmq_data:/var/lib/rabbitmq\n\n  # Temporal\n  temporal:\n    image: temporalio/auto-setup:latest\n    environment:\n      DB: postgresql\n      DB_PORT: 5432\n      POSTGRES_USER: metis\n      POSTGRES_PWD: dev_password\n      POSTGRES_SEEDS: postgres\n    ports:\n      - \"7233:7233\"\n      - \"8233:8233\"\n    depends_on:\n      - postgres\n\n  # Core App Service\n  core-app:\n    build:\n      context: .\n      dockerfile: cmd/core/Dockerfile.dev\n    environment:\n      - DATABASE_URL=postgres://metis:dev_password@postgres:5432/metis_dev\n      - REDIS_URL=redis://redis:6379\n      - RABBITMQ_URL=amqp://metis:dev_password@rabbitmq:5672/\n    ports:\n      - \"8080:8080\"\n    volumes:\n      - ./cmd/core:/app/cmd/core\n      - ./pkg:/app/pkg\n    depends_on:\n      - postgres\n      - redis\n      - rabbitmq\n\n  # ML Service\n  ml-service:\n    build:\n      context: .\n      dockerfile: cmd/ml/Dockerfile.dev\n    environment:\n      - DATABASE_URL=postgres://metis:dev_password@postgres:5432/metis_dev\n      - REDIS_URL=redis://redis:6379\n      - MODEL_STORAGE_PATH=/app/models\n    ports:\n      - \"8001:8000\"\n    volumes:\n      - ./cmd/ml:/app/cmd/ml\n      - ./models:/app/models\n    depends_on:\n      - postgres\n      - redis\n\nvolumes:\n  postgres_data:\n  redis_data:\n  localstack_data:\n  rabbitmq_data:\n</code></pre>"},{"location":"deployment-guide/#development-commands","title":"Development Commands","text":"<pre><code># Start all services\nmake dev-up\n\n# Stop all services\nmake dev-down\n\n# View logs\nmake dev-logs\n\n# Run database migrations\nmake dev-migrate\n\n# Seed development data\nmake dev-seed\n\n# Run tests\nmake test\n\n# Build and run specific service\nmake dev-build-core\nmake dev-run-core\n</code></pre>"},{"location":"deployment-guide/#makefile","title":"Makefile","text":"<pre><code># Makefile\n.PHONY: dev-up dev-down dev-logs dev-migrate dev-seed test\n\n# Development environment\ndev-up:\n    docker-compose -f docker-compose.dev.yml up -d\n    @echo \"Development environment started\"\n    @echo \"Core App: http://localhost:8080\"\n    @echo \"ML Service: http://localhost:8001\"\n    @echo \"RabbitMQ Management: http://localhost:15672\"\n\ndev-down:\n    docker-compose -f docker-compose.dev.yml down\n\ndev-logs:\n    docker-compose -f docker-compose.dev.yml logs -f\n\ndev-migrate:\n    docker-compose -f docker-compose.dev.yml exec core-app go run cmd/migrate/main.go\n\ndev-seed:\n    docker-compose -f docker-compose.dev.yml exec core-app go run cmd/seed/main.go\n\n# Testing\ntest:\n    go test ./...\n    cd cmd/ml &amp;&amp; python -m pytest\n\ntest-integration:\n    docker-compose -f docker-compose.test.yml up --abort-on-container-exit\n\n# Building\nbuild-core:\n    docker build -f cmd/core/Dockerfile -t metis/core-app:latest .\n\nbuild-ml:\n    docker build -f cmd/ml/Dockerfile -t metis/ml-service:latest .\n\nbuild-all: build-core build-ml\n\n# Linting and formatting\nlint:\n    golangci-lint run\n    cd cmd/ml &amp;&amp; black . &amp;&amp; isort . &amp;&amp; flake8\n\nformat:\n    go fmt ./...\n    cd cmd/ml &amp;&amp; black . &amp;&amp; isort .\n</code></pre>"},{"location":"deployment-guide/#kubernetes-deployment","title":"\u2638\ufe0f Kubernetes Deployment","text":""},{"location":"deployment-guide/#cluster-setup","title":"Cluster Setup","text":""},{"location":"deployment-guide/#eks-cluster-configuration","title":"EKS Cluster Configuration","text":"<pre><code># cluster-config.yaml\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: metis-production\n  region: us-west-2\n  version: \"1.28\"\n\nnodeGroups:\n  - name: core-services\n    instanceType: m5.large\n    minSize: 2\n    maxSize: 10\n    desiredCapacity: 3\n    volumeSize: 50\n    ssh:\n      allow: false\n    iam:\n      withAddonPolicies:\n        autoScaler: true\n        cloudWatch: true\n        ebs: true\n        efs: true\n        albIngress: true\n\n  - name: ml-services\n    instanceType: m5.xlarge\n    minSize: 1\n    maxSize: 5\n    desiredCapacity: 2\n    volumeSize: 100\n    ssh:\n      allow: false\n    labels:\n      workload-type: ml-intensive\n\naddons:\n  - name: vpc-cni\n  - name: coredns\n  - name: kube-proxy\n  - name: aws-ebs-csi-driver\n\ncloudWatch:\n  clusterLogging:\n    enableTypes: [\"*\"]\n</code></pre>"},{"location":"deployment-guide/#create-cluster","title":"Create Cluster","text":"<pre><code># Create EKS cluster\neksctl create cluster -f cluster-config.yaml\n\n# Install AWS Load Balancer Controller\nkubectl apply -k \"github.com/aws/eks-charts/stable/aws-load-balancer-controller//crds?ref=master\"\n\nhelm repo add eks https://aws.github.io/eks-charts\nhelm install aws-load-balancer-controller eks/aws-load-balancer-controller \\\n  -n kube-system \\\n  --set clusterName=metis-production \\\n  --set serviceAccount.create=false \\\n  --set serviceAccount.name=aws-load-balancer-controller\n</code></pre>"},{"location":"deployment-guide/#namespace-configuration","title":"Namespace Configuration","text":"<pre><code># namespaces.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: metis-production\n  labels:\n    name: metis-production\n---\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: metis-staging\n  labels:\n    name: metis-staging\n---\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: monitoring\n  labels:\n    name: monitoring\n</code></pre>"},{"location":"deployment-guide/#configmaps-and-secrets","title":"ConfigMaps and Secrets","text":""},{"location":"deployment-guide/#application-configuration","title":"Application Configuration","text":"<pre><code># configmap.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: metis-config\n  namespace: metis-production\ndata:\n  APP_ENV: \"production\"\n  LOG_LEVEL: \"info\"\n  POSTGRES_HOST: \"metis-postgres.cluster-xyz.us-west-2.rds.amazonaws.com\"\n  POSTGRES_PORT: \"5432\"\n  POSTGRES_DB: \"metis_production\"\n  REDIS_HOST: \"metis-redis.cache.amazonaws.com\"\n  REDIS_PORT: \"6379\"\n  RABBITMQ_HOST: \"metis-rabbitmq.mq.us-west-2.amazonaws.com\"\n  RABBITMQ_PORT: \"5672\"\n  TEMPORAL_HOST: \"temporal-frontend.metis-production.svc.cluster.local\"\n  TEMPORAL_PORT: \"7233\"\n  S3_BUCKET: \"metis-production-storage\"\n  AWS_REGION: \"us-west-2\"\n</code></pre>"},{"location":"deployment-guide/#secrets-management","title":"Secrets Management","text":"<pre><code># secrets.yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: metis-secrets\n  namespace: metis-production\ntype: Opaque\ndata:\n  POSTGRES_PASSWORD: &lt;base64-encoded-password&gt;\n  REDIS_PASSWORD: &lt;base64-encoded-password&gt;\n  RABBITMQ_PASSWORD: &lt;base64-encoded-password&gt;\n  JWT_SECRET: &lt;base64-encoded-jwt-secret&gt;\n  ENCRYPTION_KEY: &lt;base64-encoded-encryption-key&gt;\n  AWS_ACCESS_KEY_ID: &lt;base64-encoded-access-key&gt;\n  AWS_SECRET_ACCESS_KEY: &lt;base64-encoded-secret-key&gt;\n</code></pre>"},{"location":"deployment-guide/#application-deployments","title":"Application Deployments","text":""},{"location":"deployment-guide/#core-app-service","title":"Core App Service","text":"<pre><code># core-app-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: core-app\n  namespace: metis-production\n  labels:\n    app: core-app\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: core-app\n  template:\n    metadata:\n      labels:\n        app: core-app\n    spec:\n      containers:\n      - name: core-app\n        image: metis/core-app:v1.0.0\n        ports:\n        - containerPort: 8080\n        env:\n        - name: DATABASE_URL\n          value: \"postgres://$(POSTGRES_USER):$(POSTGRES_PASSWORD)@$(POSTGRES_HOST):$(POSTGRES_PORT)/$(POSTGRES_DB)\"\n        envFrom:\n        - configMapRef:\n            name: metis-config\n        - secretRef:\n            name: metis-secrets\n        resources:\n          requests:\n            memory: \"256Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"512Mi\"\n            cpu: \"500m\"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 5\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: core-app-service\n  namespace: metis-production\nspec:\n  selector:\n    app: core-app\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 8080\n  type: ClusterIP\n</code></pre>"},{"location":"deployment-guide/#ml-service","title":"ML Service","text":"<pre><code># ml-service-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ml-service\n  namespace: metis-production\n  labels:\n    app: ml-service\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ml-service\n  template:\n    metadata:\n      labels:\n        app: ml-service\n    spec:\n      nodeSelector:\n        workload-type: ml-intensive\n      containers:\n      - name: ml-service\n        image: metis/ml-service:v1.0.0\n        ports:\n        - containerPort: 8000\n        env:\n        - name: MODEL_STORAGE_PATH\n          value: \"/app/models\"\n        envFrom:\n        - configMapRef:\n            name: metis-config\n        - secretRef:\n            name: metis-secrets\n        resources:\n          requests:\n            memory: \"1Gi\"\n            cpu: \"500m\"\n          limits:\n            memory: \"2Gi\"\n            cpu: \"1000m\"\n        volumeMounts:\n        - name: model-storage\n          mountPath: /app/models\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8000\n          initialDelaySeconds: 60\n          periodSeconds: 30\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8000\n          initialDelaySeconds: 30\n          periodSeconds: 10\n      volumes:\n      - name: model-storage\n        persistentVolumeClaim:\n          claimName: ml-models-pvc\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: ml-service\n  namespace: metis-production\nspec:\n  selector:\n    app: ml-service\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 8000\n  type: ClusterIP\n</code></pre>"},{"location":"deployment-guide/#ingress-configuration","title":"Ingress Configuration","text":"<pre><code># ingress.yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: metis-ingress\n  namespace: metis-production\n  annotations:\n    kubernetes.io/ingress.class: alb\n    alb.ingress.kubernetes.io/scheme: internet-facing\n    alb.ingress.kubernetes.io/target-type: ip\n    alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:us-west-2:123456789:certificate/abc123\n    alb.ingress.kubernetes.io/ssl-policy: ELBSecurityPolicy-TLS-1-2-2017-01\n    alb.ingress.kubernetes.io/listen-ports: '[{\"HTTP\": 80}, {\"HTTPS\": 443}]'\n    alb.ingress.kubernetes.io/ssl-redirect: '443'\nspec:\n  rules:\n  - host: api.metis.com\n    http:\n      paths:\n      - path: /api/v1/ml\n        pathType: Prefix\n        backend:\n          service:\n            name: ml-service\n            port:\n              number: 80\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: core-app-service\n            port:\n              number: 80\n</code></pre>"},{"location":"deployment-guide/#cicd-pipeline","title":"\ud83d\ude80 CI/CD Pipeline","text":""},{"location":"deployment-guide/#github-actions-workflow","title":"GitHub Actions Workflow","text":"<pre><code># .github/workflows/deploy.yml\nname: Deploy to Production\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\nenv:\n  AWS_REGION: us-west-2\n  EKS_CLUSTER_NAME: metis-production\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Set up Go\n      uses: actions/setup-go@v3\n      with:\n        go-version: 1.21\n\n    - name: Set up Python\n      uses: actions/setup-python@v3\n      with:\n        python-version: 3.11\n\n    - name: Run Go tests\n      run: |\n        go mod download\n        go test ./...\n\n    - name: Run Python tests\n      run: |\n        cd cmd/ml\n        pip install -r requirements.txt\n        python -m pytest\n\n    - name: Run linting\n      run: |\n        golangci-lint run\n        cd cmd/ml &amp;&amp; black --check . &amp;&amp; isort --check . &amp;&amp; flake8\n\n  build:\n    needs: test\n    runs-on: ubuntu-latest\n    if: github.ref == 'refs/heads/main'\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Configure AWS credentials\n      uses: aws-actions/configure-aws-credentials@v2\n      with:\n        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n        aws-region: ${{ env.AWS_REGION }}\n\n    - name: Login to Amazon ECR\n      id: login-ecr\n      uses: aws-actions/amazon-ecr-login@v1\n\n    - name: Build and push Core App image\n      env:\n        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}\n        ECR_REPOSITORY: metis/core-app\n        IMAGE_TAG: ${{ github.sha }}\n      run: |\n        docker build -f cmd/core/Dockerfile -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .\n        docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG\n        docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:latest\n        docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest\n\n    - name: Build and push ML Service image\n      env:\n        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}\n        ECR_REPOSITORY: metis/ml-service\n        IMAGE_TAG: ${{ github.sha }}\n      run: |\n        docker build -f cmd/ml/Dockerfile -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .\n        docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG\n        docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:latest\n        docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest\n\n  deploy:\n    needs: build\n    runs-on: ubuntu-latest\n    if: github.ref == 'refs/heads/main'\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Configure AWS credentials\n      uses: aws-actions/configure-aws-credentials@v2\n      with:\n        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n        aws-region: ${{ env.AWS_REGION }}\n\n    - name: Update kubeconfig\n      run: |\n        aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.EKS_CLUSTER_NAME }}\n\n    - name: Deploy to Kubernetes\n      env:\n        IMAGE_TAG: ${{ github.sha }}\n      run: |\n        # Update image tags in deployment files\n        sed -i \"s|metis/core-app:.*|metis/core-app:$IMAGE_TAG|g\" k8s/core-app-deployment.yaml\n        sed -i \"s|metis/ml-service:.*|metis/ml-service:$IMAGE_TAG|g\" k8s/ml-service-deployment.yaml\n\n        # Apply configurations\n        kubectl apply -f k8s/\n\n        # Wait for rollout to complete\n        kubectl rollout status deployment/core-app -n metis-production\n        kubectl rollout status deployment/ml-service -n metis-production\n</code></pre>"},{"location":"deployment-guide/#monitoring-logging","title":"\ud83d\udcca Monitoring &amp; Logging","text":""},{"location":"deployment-guide/#prometheus-configuration","title":"Prometheus Configuration","text":"<pre><code># prometheus-config.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: prometheus-config\n  namespace: monitoring\ndata:\n  prometheus.yml: |\n    global:\n      scrape_interval: 15s\n      evaluation_interval: 15s\n\n    rule_files:\n      - \"metis_rules.yml\"\n\n    scrape_configs:\n      - job_name: 'kubernetes-pods'\n        kubernetes_sd_configs:\n          - role: pod\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n            action: keep\n            regex: true\n          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]\n            action: replace\n            target_label: __metrics_path__\n            regex: (.+)\n\n      - job_name: 'metis-core-app'\n        static_configs:\n          - targets: ['core-app-service.metis-production.svc.cluster.local:80']\n        metrics_path: /metrics\n\n      - job_name: 'metis-ml-service'\n        static_configs:\n          - targets: ['ml-service.metis-production.svc.cluster.local:80']\n        metrics_path: /metrics\n\n    alerting:\n      alertmanagers:\n        - static_configs:\n            - targets:\n              - alertmanager.monitoring.svc.cluster.local:9093\n</code></pre>"},{"location":"deployment-guide/#grafana-dashboards","title":"Grafana Dashboards","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"Metis Platform Overview\",\n    \"panels\": [\n      {\n        \"title\": \"Request Rate\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(http_requests_total[5m])\",\n            \"legendFormat\": \"{{service}}\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Response Time\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))\",\n            \"legendFormat\": \"95th percentile\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Error Rate\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(http_requests_total{status=~\\\"5..\\\"}[5m])\",\n            \"legendFormat\": \"5xx errors\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"deployment-guide/#security-considerations","title":"\ud83d\udd12 Security Considerations","text":""},{"location":"deployment-guide/#network-security","title":"Network Security","text":"<pre><code># network-policy.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: metis-network-policy\n  namespace: metis-production\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: metis-production\n    - podSelector: {}\n  egress:\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: metis-production\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 443\n    - protocol: TCP\n      port: 53\n    - protocol: UDP\n      port: 53\n</code></pre>"},{"location":"deployment-guide/#pod-security-standards","title":"Pod Security Standards","text":"<pre><code># pod-security-policy.yaml\napiVersion: policy/v1beta1\nkind: PodSecurityPolicy\nmetadata:\n  name: metis-psp\nspec:\n  privileged: false\n  allowPrivilegeEscalation: false\n  requiredDropCapabilities:\n    - ALL\n  volumes:\n    - 'configMap'\n    - 'emptyDir'\n    - 'projected'\n    - 'secret'\n    - 'downwardAPI'\n    - 'persistentVolumeClaim'\n  runAsUser:\n    rule: 'MustRunAsNonRoot'\n  seLinux:\n    rule: 'RunAsAny'\n  fsGroup:\n    rule: 'RunAsAny'\n</code></pre>"},{"location":"deployment-guide/#disaster-recovery","title":"\ud83d\udea8 Disaster Recovery","text":""},{"location":"deployment-guide/#backup-strategy","title":"Backup Strategy","text":"<pre><code>#!/bin/bash\n# backup-script.sh\n\n# Database backup\nkubectl exec -n metis-production deployment/postgres -- pg_dump -U metis metis_production &gt; backup-$(date +%Y%m%d).sql\n\n# Upload to S3\naws s3 cp backup-$(date +%Y%m%d).sql s3://metis-backups/database/\n\n# Kubernetes configuration backup\nkubectl get all -n metis-production -o yaml &gt; k8s-backup-$(date +%Y%m%d).yaml\naws s3 cp k8s-backup-$(date +%Y%m%d).yaml s3://metis-backups/k8s/\n\n# Clean up local files\nrm backup-$(date +%Y%m%d).sql k8s-backup-$(date +%Y%m%d).yaml\n</code></pre>"},{"location":"deployment-guide/#recovery-procedures","title":"Recovery Procedures","text":"<pre><code>#!/bin/bash\n# recovery-script.sh\n\n# Restore database\naws s3 cp s3://metis-backups/database/backup-20240101.sql .\nkubectl exec -n metis-production deployment/postgres -- psql -U metis -d metis_production &lt; backup-20240101.sql\n\n# Restore Kubernetes resources\naws s3 cp s3://metis-backups/k8s/k8s-backup-20240101.yaml .\nkubectl apply -f k8s-backup-20240101.yaml\n</code></pre>"},{"location":"deployment-guide/#deployment-checklist","title":"\ud83d\udccb Deployment Checklist","text":""},{"location":"deployment-guide/#pre-deployment","title":"Pre-deployment","text":"<ul> <li>[ ] All tests passing</li> <li>[ ] Security scan completed</li> <li>[ ] Performance testing completed</li> <li>[ ] Database migrations tested</li> <li>[ ] Backup procedures verified</li> <li>[ ] Monitoring alerts configured</li> </ul>"},{"location":"deployment-guide/#deployment","title":"Deployment","text":"<ul> <li>[ ] Blue-green deployment strategy</li> <li>[ ] Health checks passing</li> <li>[ ] Database migrations applied</li> <li>[ ] Configuration updated</li> <li>[ ] SSL certificates valid</li> <li>[ ] Load balancer configured</li> </ul>"},{"location":"deployment-guide/#post-deployment","title":"Post-deployment","text":"<ul> <li>[ ] Application health verified</li> <li>[ ] Monitoring dashboards updated</li> <li>[ ] Performance metrics baseline</li> <li>[ ] Error rates within acceptable limits</li> <li>[ ] User acceptance testing</li> <li>[ ] Documentation updated</li> </ul> <p>This deployment guide ensures reliable, secure, and scalable deployment of the Metis platform across all environments.</p>"},{"location":"go-guidelines/","title":"Go Coding Guidelines","text":"<p>Comprehensive Go coding standards for the Metis platform, ensuring consistency, maintainability, and performance across the codebase.</p>"},{"location":"go-guidelines/#overview","title":"\ud83d\udccb Overview","text":"<p>These guidelines reflect Go's best practices and are designed to prevent common anti-patterns while maintaining code quality across our multi-tenant SAAS platform.</p> <p>Key Principles: - Simplicity: Write clear, readable code - Consistency: Follow established patterns - Performance: Optimize for efficiency - Maintainability: Code should be easy to modify</p>"},{"location":"go-guidelines/#code-organization","title":"\ud83d\udcc1 Code Organization","text":""},{"location":"go-guidelines/#file-structure","title":"File Structure","text":"<ul> <li>Maximum file length: 500 lines (excluding comments)</li> <li>Single purpose: Each file should have one well-defined responsibility</li> <li>Related functionality: Group related code together</li> </ul>"},{"location":"go-guidelines/#file-element-order","title":"File Element Order","text":"<pre><code>// 1. Package declaration\npackage main\n\n// 2. Imports (grouped and ordered)\nimport (\n    // Standard library\n    \"context\"\n    \"fmt\"\n    \"time\"\n\n    // Third-party packages\n    \"github.com/gin-gonic/gin\"\n    \"github.com/temporal-io/sdk-go/workflow\"\n\n    // Internal packages\n    \"github.com/metis/pkg/auth\"\n    \"github.com/metis/pkg/database\"\n)\n\n// 3. Constants\nconst (\n    MaxRetryCount = 3\n    DefaultTimeout = 30 * time.Second\n)\n\n// 4. Variables\nvar (\n    ErrNotFound = errors.New(\"resource not found\")\n    ErrInvalidInput = errors.New(\"invalid input\")\n)\n\n// 5. Types\ntype User struct {\n    ID    string\n    Email string\n}\n\n// 6. Functions and Methods\nfunc NewUser(email string) *User {\n    return &amp;User{\n        ID:    generateID(),\n        Email: email,\n    }\n}\n</code></pre>"},{"location":"go-guidelines/#naming-conventions","title":"\ud83c\udff7\ufe0f Naming Conventions","text":""},{"location":"go-guidelines/#general-rules","title":"General Rules","text":"<ul> <li>Short, concise names in small scopes</li> <li>Descriptive names in larger scopes</li> <li>No underscores in package names</li> <li>CamelCase for variables and functions</li> <li>PascalCase for exported names</li> </ul>"},{"location":"go-guidelines/#specific-conventions","title":"Specific Conventions","text":""},{"location":"go-guidelines/#packages","title":"Packages","text":"<pre><code>// Good\npackage api\npackage config\npackage database\n\n// Bad\npackage api_handlers\npackage db_utils\n</code></pre>"},{"location":"go-guidelines/#functions","title":"Functions","text":"<pre><code>// Good - Use verbs\nfunc GetUser(ctx context.Context, id string) (*User, error)\nfunc CreateOrder(order *Order) error\nfunc ValidateInput(data map[string]interface{}) error\n\n// Bad\nfunc User(id string) (*User, error)\nfunc Order(order *Order) error\n</code></pre>"},{"location":"go-guidelines/#variables","title":"Variables","text":"<pre><code>// Good - Use nouns\nvar user *User\nvar orderList []Order\nvar dbConnection *sql.DB\n\n// Bad\nvar getUserResult *User\nvar createOrderFunc func()\n</code></pre>"},{"location":"go-guidelines/#constants","title":"Constants","text":"<pre><code>// Good\nconst (\n    MaxRetryCount     = 3\n    DefaultTimeout    = 30 * time.Second\n    DatabaseURL       = \"postgres://localhost:5432/metis\"\n)\n</code></pre>"},{"location":"go-guidelines/#error-variables","title":"Error Variables","text":"<pre><code>// Good - Prefix with Err\nvar (\n    ErrNotFound      = errors.New(\"resource not found\")\n    ErrUnauthorized  = errors.New(\"unauthorized access\")\n    ErrInvalidInput  = errors.New(\"invalid input provided\")\n)\n</code></pre>"},{"location":"go-guidelines/#interfaces","title":"Interfaces","text":"<pre><code>// Good - Add 'er' suffix when appropriate\ntype Reader interface {\n    Read([]byte) (int, error)\n}\n\ntype UserRepository interface {\n    GetUser(ctx context.Context, id string) (*User, error)\n    CreateUser(ctx context.Context, user *User) error\n}\n</code></pre>"},{"location":"go-guidelines/#documentation","title":"\ud83d\udcdd Documentation","text":""},{"location":"go-guidelines/#package-documentation","title":"Package Documentation","text":"<pre><code>// Package auth provides authentication and authorization functionality\n// for the Metis platform. It includes JWT token management, session\n// handling, and multi-tenant security features.\npackage auth\n</code></pre>"},{"location":"go-guidelines/#function-documentation","title":"Function Documentation","text":"<pre><code>// GetUser retrieves a user by ID from the database.\n// Returns ErrNotFound if the user doesn't exist.\n// The context should include tenant information for proper isolation.\nfunc GetUser(ctx context.Context, id string) (*User, error) {\n    // Implementation\n}\n</code></pre>"},{"location":"go-guidelines/#type-documentation","title":"Type Documentation","text":"<pre><code>// User represents a system user with authentication details.\n// It includes fields for identification, tenant association,\n// and access control within the multi-tenant architecture.\ntype User struct {\n    ID       string    `json:\"id\" db:\"id\"`\n    TenantID string    `json:\"tenant_id\" db:\"tenant_id\"`\n    Email    string    `json:\"email\" db:\"email\"`\n    Name     string    `json:\"name\" db:\"name\"`\n    Created  time.Time `json:\"created_at\" db:\"created_at\"`\n}\n</code></pre>"},{"location":"go-guidelines/#function-design","title":"\ud83d\udd27 Function Design","text":""},{"location":"go-guidelines/#size-and-complexity","title":"Size and Complexity","text":"<ul> <li>Maximum length: 50 lines</li> <li>Maximum nesting: 3 levels of control structures</li> <li>Single responsibility: Functions should do one thing well</li> </ul>"},{"location":"go-guidelines/#parameters","title":"Parameters","text":"<pre><code>// Good - Maximum 5 parameters\nfunc ProcessLoan(ctx context.Context, userID, loanID string, amount float64, urgent bool) error\n\n// Better - Use structs for more parameters\ntype LoanRequest struct {\n    UserID   string\n    LoanID   string\n    Amount   float64\n    Urgent   bool\n    Metadata map[string]interface{}\n}\n\nfunc ProcessLoan(ctx context.Context, request LoanRequest) error\n</code></pre>"},{"location":"go-guidelines/#return-values","title":"Return Values","text":"<pre><code>// Good - Return errors as last value\nfunc GetUser(ctx context.Context, id string) (*User, error)\n\n// Good - Use named returns for documentation\nfunc CalculateInterest(principal, rate float64, years int) (interest, total float64, err error) {\n    if principal &lt;= 0 || rate &lt;= 0 || years &lt;= 0 {\n        err = ErrInvalidInput\n        return\n    }\n\n    interest = principal * rate * float64(years) / 100\n    total = principal + interest\n    return\n}\n</code></pre>"},{"location":"go-guidelines/#error-handling","title":"\u274c Error Handling","text":""},{"location":"go-guidelines/#error-types","title":"Error Types","text":"<pre><code>// Custom error types for domain-specific errors\ntype ValidationError struct {\n    Field   string\n    Message string\n}\n\nfunc (e ValidationError) Error() string {\n    return fmt.Sprintf(\"validation failed for field %s: %s\", e.Field, e.Message)\n}\n\n// Sentinel errors for common cases\nvar (\n    ErrUserNotFound    = errors.New(\"user not found\")\n    ErrInvalidTenant   = errors.New(\"invalid tenant\")\n    ErrDuplicateEmail  = errors.New(\"email already exists\")\n)\n</code></pre>"},{"location":"go-guidelines/#error-wrapping","title":"Error Wrapping","text":"<pre><code>func ProcessOrder(ctx context.Context, order *Order) error {\n    if err := validateOrder(order); err != nil {\n        return fmt.Errorf(\"invalid order: %w\", err)\n    }\n\n    if err := saveOrder(ctx, order); err != nil {\n        return fmt.Errorf(\"failed to save order %s: %w\", order.ID, err)\n    }\n\n    return nil\n}\n</code></pre>"},{"location":"go-guidelines/#error-handling-patterns","title":"Error Handling Patterns","text":"<pre><code>// Good - Handle errors immediately\nfunc GetUserProfile(ctx context.Context, userID string) (*UserProfile, error) {\n    user, err := userRepo.GetUser(ctx, userID)\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to get user: %w\", err)\n    }\n\n    profile, err := profileRepo.GetProfile(ctx, userID)\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to get profile: %w\", err)\n    }\n\n    return &amp;UserProfile{User: user, Profile: profile}, nil\n}\n</code></pre>"},{"location":"go-guidelines/#testing","title":"\ud83e\uddea Testing","text":""},{"location":"go-guidelines/#test-structure","title":"Test Structure","text":"<pre><code>func TestGetUser(t *testing.T) {\n    tests := []struct {\n        name    string\n        userID  string\n        want    *User\n        wantErr error\n    }{\n        {\n            name:    \"valid user\",\n            userID:  \"user-123\",\n            want:    &amp;User{ID: \"user-123\", Email: \"test@example.com\"},\n            wantErr: nil,\n        },\n        {\n            name:    \"user not found\",\n            userID:  \"nonexistent\",\n            want:    nil,\n            wantErr: ErrUserNotFound,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            got, err := GetUser(context.Background(), tt.userID)\n\n            if !errors.Is(err, tt.wantErr) {\n                t.Errorf(\"GetUser() error = %v, wantErr %v\", err, tt.wantErr)\n                return\n            }\n\n            if !reflect.DeepEqual(got, tt.want) {\n                t.Errorf(\"GetUser() = %v, want %v\", got, tt.want)\n            }\n        })\n    }\n}\n</code></pre>"},{"location":"go-guidelines/#test-requirements","title":"Test Requirements","text":"<ul> <li>Minimum coverage: 80%</li> <li>Test independence: Tests should not depend on each other</li> <li>Both paths: Test success and failure scenarios</li> <li>Descriptive names: Test names should describe the scenario</li> </ul>"},{"location":"go-guidelines/#package-design","title":"\ud83d\udce6 Package Design","text":""},{"location":"go-guidelines/#package-principles","title":"Package Principles","text":"<ul> <li>Single responsibility: Each package should have one clear purpose</li> <li>Minimal dependencies: Reduce coupling between packages</li> <li>Internal packages: Use <code>internal/</code> for implementation details</li> </ul>"},{"location":"go-guidelines/#package-structure","title":"Package Structure","text":"<pre><code>pkg/\n\u251c\u2500\u2500 auth/           # Authentication and authorization\n\u251c\u2500\u2500 database/       # Database operations and models\n\u251c\u2500\u2500 config/         # Configuration management\n\u251c\u2500\u2500 logging/        # Structured logging\n\u251c\u2500\u2500 workflows/      # Temporal workflow definitions\n\u2514\u2500\u2500 internal/       # Internal implementation details\n    \u251c\u2500\u2500 models/     # Internal data models\n    \u2514\u2500\u2500 utils/      # Internal utilities\n</code></pre>"},{"location":"go-guidelines/#concurrency","title":"\ud83d\udd04 Concurrency","text":""},{"location":"go-guidelines/#goroutines","title":"Goroutines","text":"<pre><code>// Good - Proper goroutine lifecycle management\nfunc ProcessBatch(ctx context.Context, items []Item) error {\n    errChan := make(chan error, len(items))\n\n    for _, item := range items {\n        go func(i Item) {\n            defer func() {\n                if r := recover(); r != nil {\n                    errChan &lt;- fmt.Errorf(\"panic processing item %s: %v\", i.ID, r)\n                }\n            }()\n\n            errChan &lt;- processItem(ctx, i)\n        }(item)\n    }\n\n    for range items {\n        if err := &lt;-errChan; err != nil {\n            return fmt.Errorf(\"batch processing failed: %w\", err)\n        }\n    }\n\n    return nil\n}\n</code></pre>"},{"location":"go-guidelines/#channels","title":"Channels","text":"<pre><code>// Good - Proper channel usage\nfunc WorkerPool(ctx context.Context, jobs &lt;-chan Job, results chan&lt;- Result) {\n    defer close(results)\n\n    for {\n        select {\n        case job, ok := &lt;-jobs:\n            if !ok {\n                return // Channel closed\n            }\n\n            result := processJob(job)\n\n            select {\n            case results &lt;- result:\n            case &lt;-ctx.Done():\n                return\n            }\n\n        case &lt;-ctx.Done():\n            return\n        }\n    }\n}\n</code></pre>"},{"location":"go-guidelines/#performance-considerations","title":"\u26a1 Performance Considerations","text":""},{"location":"go-guidelines/#memory-management","title":"Memory Management","text":"<pre><code>// Good - Pre-allocate slices when size is known\nfunc ProcessUsers(users []User) []ProcessedUser {\n    processed := make([]ProcessedUser, 0, len(users))\n\n    for _, user := range users {\n        processed = append(processed, processUser(user))\n    }\n\n    return processed\n}\n\n// Good - Use sync.Pool for frequently allocated objects\nvar bufferPool = sync.Pool{\n    New: func() interface{} {\n        return make([]byte, 0, 1024)\n    },\n}\n\nfunc ProcessData(data []byte) ([]byte, error) {\n    buf := bufferPool.Get().([]byte)\n    defer bufferPool.Put(buf[:0])\n\n    // Process data using buf\n    return processWithBuffer(data, buf)\n}\n</code></pre>"},{"location":"go-guidelines/#string-operations","title":"String Operations","text":"<pre><code>// Good - Use strings.Builder for concatenation\nfunc BuildQuery(fields []string, table string) string {\n    var builder strings.Builder\n    builder.WriteString(\"SELECT \")\n\n    for i, field := range fields {\n        if i &gt; 0 {\n            builder.WriteString(\", \")\n        }\n        builder.WriteString(field)\n    }\n\n    builder.WriteString(\" FROM \")\n    builder.WriteString(table)\n\n    return builder.String()\n}\n</code></pre>"},{"location":"go-guidelines/#anti-patterns-to-avoid","title":"\ud83d\udeab Anti-Patterns to Avoid","text":""},{"location":"go-guidelines/#global-variables","title":"Global Variables","text":"<pre><code>// Bad\nvar db *sql.DB\n\nfunc init() {\n    db = connectToDatabase()\n}\n\n// Good - Use dependency injection\ntype UserService struct {\n    db *sql.DB\n}\n\nfunc NewUserService(db *sql.DB) *UserService {\n    return &amp;UserService{db: db}\n}\n</code></pre>"},{"location":"go-guidelines/#panic-usage","title":"Panic Usage","text":"<pre><code>// Bad - Don't use panic for normal error handling\nfunc GetUser(id string) *User {\n    user, err := userRepo.Get(id)\n    if err != nil {\n        panic(err) // Bad!\n    }\n    return user\n}\n\n// Good - Return errors\nfunc GetUser(ctx context.Context, id string) (*User, error) {\n    user, err := userRepo.Get(ctx, id)\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to get user: %w\", err)\n    }\n    return user, nil\n}\n</code></pre>"},{"location":"go-guidelines/#code-review-checklist","title":"\ud83d\udd0d Code Review Checklist","text":""},{"location":"go-guidelines/#functionality","title":"Functionality","text":"<ul> <li>[ ] Code works as expected</li> <li>[ ] Edge cases are handled</li> <li>[ ] Error handling is appropriate</li> <li>[ ] Tests cover the functionality</li> </ul>"},{"location":"go-guidelines/#code-quality","title":"Code Quality","text":"<ul> <li>[ ] Follows naming conventions</li> <li>[ ] Functions are appropriately sized</li> <li>[ ] Code is well-documented</li> <li>[ ] No code duplication</li> </ul>"},{"location":"go-guidelines/#performance","title":"Performance","text":"<ul> <li>[ ] No obvious performance issues</li> <li>[ ] Appropriate data structures used</li> <li>[ ] Memory usage is reasonable</li> <li>[ ] Concurrency is handled correctly</li> </ul>"},{"location":"go-guidelines/#security","title":"Security","text":"<ul> <li>[ ] Input validation is present</li> <li>[ ] No sensitive data in logs</li> <li>[ ] Proper error messages (no information leakage)</li> <li>[ ] Authentication/authorization checks</li> </ul>"},{"location":"go-guidelines/#tools-linting","title":"\ud83d\udee0\ufe0f Tools &amp; Linting","text":""},{"location":"go-guidelines/#required-tools","title":"Required Tools","text":"<ul> <li>golangci-lint: Comprehensive linting</li> <li>go fmt: Code formatting</li> <li>go vet: Static analysis</li> <li>staticcheck: Advanced static analysis</li> </ul>"},{"location":"go-guidelines/#pre-commit-setup","title":"Pre-commit Setup","text":"<pre><code># Install pre-commit hooks\nmake pre-commit-install\n\n# Run linting\nmake lint\n\n# Run tests\nmake test\n</code></pre>"},{"location":"go-guidelines/#ide-configuration","title":"IDE Configuration","text":"<p>Configure your IDE to: - Run <code>go fmt</code> on save - Show linting errors inline - Run tests automatically - Import organization</p>"},{"location":"go-guidelines/#metrics-monitoring","title":"\ud83d\udcca Metrics &amp; Monitoring","text":""},{"location":"go-guidelines/#code-metrics","title":"Code Metrics","text":"<pre><code>// Good - Add metrics to important functions\nfunc ProcessLoanApplication(ctx context.Context, app *LoanApplication) error {\n    start := time.Now()\n    defer func() {\n        processingDuration.WithLabelValues(\"loan_application\").Observe(time.Since(start).Seconds())\n    }()\n\n    // Processing logic\n    return nil\n}\n</code></pre>"},{"location":"go-guidelines/#logging","title":"Logging","text":"<pre><code>// Good - Structured logging\nfunc ProcessUser(ctx context.Context, userID string) error {\n    logger := logging.FromContext(ctx).With(\n        \"user_id\", userID,\n        \"operation\", \"process_user\",\n    )\n\n    logger.Info(\"starting user processing\")\n\n    if err := validateUser(ctx, userID); err != nil {\n        logger.Error(\"user validation failed\", \"error\", err)\n        return fmt.Errorf(\"validation failed: %w\", err)\n    }\n\n    logger.Info(\"user processing completed successfully\")\n    return nil\n}\n</code></pre> <p>These guidelines ensure consistent, maintainable, and performant Go code across the Metis platform. Regular review and updates keep them aligned with evolving best practices.</p>"},{"location":"python-guidelines/","title":"Python Coding Guidelines","text":"<p>Comprehensive Python coding standards for the Metis platform, focusing on ML services, FastAPI development, and data processing components.</p>"},{"location":"python-guidelines/#overview","title":"\ud83d\udccb Overview","text":"<p>These guidelines ensure consistent, maintainable, and performant Python code across our ML services, data processing pipelines, and API endpoints.</p> <p>Key Principles: - Readability: Code should be self-documenting - Type Safety: Use type hints extensively - Performance: Optimize for ML workloads - Maintainability: Follow established patterns</p>"},{"location":"python-guidelines/#python-version-environment","title":"\ud83d\udc0d Python Version &amp; Environment","text":""},{"location":"python-guidelines/#python-version","title":"Python Version","text":"<ul> <li>Minimum: Python 3.11+</li> <li>Recommended: Python 3.12+</li> <li>Virtual Environment: Always use virtual environments</li> </ul>"},{"location":"python-guidelines/#dependency-management","title":"Dependency Management","text":"<pre><code># pyproject.toml\n[tool.poetry]\nname = \"metis-ml\"\nversion = \"1.0.0\"\ndescription = \"Metis ML Services\"\nauthors = [\"Metis Team &lt;team@metis.com&gt;\"]\n\n[tool.poetry.dependencies]\npython = \"^3.11\"\nfastapi = \"^0.104.0\"\nuvicorn = \"^0.24.0\"\npydantic = \"^2.5.0\"\nnumpy = \"^1.25.0\"\npandas = \"^2.1.0\"\nscikit-learn = \"^1.3.0\"\n</code></pre>"},{"location":"python-guidelines/#code-organization","title":"\ud83d\udcc1 Code Organization","text":""},{"location":"python-guidelines/#project-structure","title":"Project Structure","text":"<pre><code>cmd/ml/\n\u251c\u2500\u2500 main.py                 # FastAPI application entry point\n\u251c\u2500\u2500 ml_server/             # ML server modules\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 api/               # API endpoints\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 ocr.py\n\u2502   \u2502   \u2514\u2500\u2500 risk.py\n\u2502   \u251c\u2500\u2500 models/            # Model implementations\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 base.py\n\u2502   \u2502   \u251c\u2500\u2500 ocr_model.py\n\u2502   \u2502   \u2514\u2500\u2500 risk_model.py\n\u2502   \u251c\u2500\u2500 services/          # Business logic\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 document_processor.py\n\u2502   \u2502   \u2514\u2500\u2500 feature_extractor.py\n\u2502   \u2514\u2500\u2500 utils/             # Utilities\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 config.py\n\u2502       \u2514\u2500\u2500 logging.py\n\u2514\u2500\u2500 tests/                 # Test files\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 test_api/\n    \u251c\u2500\u2500 test_models/\n    \u2514\u2500\u2500 test_services/\n</code></pre>"},{"location":"python-guidelines/#file-organization","title":"File Organization","text":"<pre><code>\"\"\"Module docstring describing the purpose and functionality.\"\"\"\n\n# Standard library imports\nimport asyncio\nimport logging\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Union\n\n# Third-party imports\nimport numpy as np\nimport pandas as pd\nfrom fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel, Field\n\n# Local imports\nfrom ml_server.models.base import BaseModel\nfrom ml_server.utils.config import settings\nfrom ml_server.utils.logging import get_logger\n\n# Constants\nDEFAULT_TIMEOUT = 30\nMAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB\n\n# Module-level variables\nlogger = get_logger(__name__)\n\n# Classes and functions follow...\n</code></pre>"},{"location":"python-guidelines/#naming-conventions","title":"\ud83c\udff7\ufe0f Naming Conventions","text":""},{"location":"python-guidelines/#general-rules","title":"General Rules","text":"<ul> <li>snake_case: Variables, functions, modules</li> <li>PascalCase: Classes, exceptions</li> <li>UPPER_CASE: Constants</li> <li>_private: Private attributes/methods</li> </ul>"},{"location":"python-guidelines/#specific-examples","title":"Specific Examples","text":"<pre><code># Variables and functions\nuser_id = \"user-123\"\ndocument_path = Path(\"/path/to/document\")\n\ndef process_document(file_path: Path) -&gt; Dict[str, Any]:\n    \"\"\"Process document and extract data.\"\"\"\n    pass\n\ndef calculate_risk_score(features: np.ndarray) -&gt; float:\n    \"\"\"Calculate risk score from features.\"\"\"\n    pass\n\n# Classes\nclass DocumentProcessor:\n    \"\"\"Handles document processing operations.\"\"\"\n\n    def __init__(self, model_path: Path):\n        self._model_path = model_path\n        self._model = None\n\n    def _load_model(self) -&gt; None:\n        \"\"\"Load the ML model (private method).\"\"\"\n        pass\n\nclass OCRModel(BaseModel):\n    \"\"\"OCR model for text extraction.\"\"\"\n    pass\n\n# Constants\nMAX_RETRY_COUNT = 3\nDEFAULT_MODEL_PATH = Path(\"models/ocr/latest.pkl\")\nSUPPORTED_FORMATS = [\"pdf\", \"jpg\", \"png\"]\n\n# Exceptions\nclass ModelLoadError(Exception):\n    \"\"\"Raised when model loading fails.\"\"\"\n    pass\n\nclass InvalidDocumentError(ValueError):\n    \"\"\"Raised when document format is invalid.\"\"\"\n    pass\n</code></pre>"},{"location":"python-guidelines/#type-hints-documentation","title":"\ud83d\udcdd Type Hints &amp; Documentation","text":""},{"location":"python-guidelines/#type-hints","title":"Type Hints","text":"<pre><code>from typing import Dict, List, Optional, Union, Tuple, Any\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\n\n# Function signatures\ndef extract_features(\n    document: Path,\n    model_type: str = \"default\",\n    confidence_threshold: float = 0.8\n) -&gt; Tuple[np.ndarray, Dict[str, float]]:\n    \"\"\"Extract features from document.\n\n    Args:\n        document: Path to the document file\n        model_type: Type of model to use for extraction\n        confidence_threshold: Minimum confidence for feature extraction\n\n    Returns:\n        Tuple of (features array, confidence scores)\n\n    Raises:\n        InvalidDocumentError: If document format is not supported\n        ModelLoadError: If model fails to load\n    \"\"\"\n    pass\n\n# Class with type hints\nclass RiskModel:\n    \"\"\"Risk assessment model.\"\"\"\n\n    def __init__(self, model_path: Path) -&gt; None:\n        self.model_path = model_path\n        self._model: Optional[Any] = None\n        self._features: List[str] = []\n\n    def predict(self, features: np.ndarray) -&gt; Dict[str, Union[float, str]]:\n        \"\"\"Predict risk score.\"\"\"\n        pass\n</code></pre>"},{"location":"python-guidelines/#docstring-standards","title":"Docstring Standards","text":"<pre><code>def process_loan_application(\n    application_data: Dict[str, Any],\n    model_version: str = \"latest\"\n) -&gt; Dict[str, Any]:\n    \"\"\"Process loan application through ML pipeline.\n\n    This function orchestrates the complete loan processing workflow,\n    including document validation, feature extraction, and risk assessment.\n\n    Args:\n        application_data: Dictionary containing application information\n            - applicant_id (str): Unique applicant identifier\n            - documents (List[Path]): List of document file paths\n            - amount (float): Requested loan amount\n        model_version: Version of the model to use for processing\n\n    Returns:\n        Dictionary containing processing results:\n            - risk_score (float): Calculated risk score (0.0 to 1.0)\n            - decision (str): Approval decision (\"approved\", \"rejected\", \"review\")\n            - confidence (float): Model confidence in the decision\n            - processing_time (float): Time taken for processing in seconds\n\n    Raises:\n        InvalidDocumentError: If any document is in unsupported format\n        ModelLoadError: If the specified model version cannot be loaded\n        ProcessingError: If processing fails due to data issues\n\n    Example:\n        &gt;&gt;&gt; application = {\n        ...     \"applicant_id\": \"app-123\",\n        ...     \"documents\": [Path(\"pan.jpg\"), Path(\"aadhar.pdf\")],\n        ...     \"amount\": 50000.0\n        ... }\n        &gt;&gt;&gt; result = process_loan_application(application)\n        &gt;&gt;&gt; print(result[\"decision\"])\n        \"approved\"\n    \"\"\"\n    pass\n</code></pre>"},{"location":"python-guidelines/#fastapi-development","title":"\ud83d\ude80 FastAPI Development","text":""},{"location":"python-guidelines/#application-structure","title":"Application Structure","text":"<pre><code># main.py\nfrom fastapi import FastAPI, HTTPException, Depends\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom contextlib import asynccontextmanager\nimport uvicorn\n\nfrom ml_server.api import ocr, risk\nfrom ml_server.utils.config import settings\nfrom ml_server.utils.logging import setup_logging\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"Manage application lifespan.\"\"\"\n    # Startup\n    setup_logging()\n    logger.info(\"Starting ML API server\")\n\n    # Load models\n    await load_models()\n\n    yield\n\n    # Shutdown\n    logger.info(\"Shutting down ML API server\")\n    await cleanup_models()\n\napp = FastAPI(\n    title=\"Metis ML API\",\n    description=\"Machine Learning services for the Metis platform\",\n    version=\"1.0.0\",\n    lifespan=lifespan\n)\n\n# Middleware\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=settings.allowed_origins,\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Include routers\napp.include_router(ocr.router, prefix=\"/api/v1/ocr\", tags=[\"OCR\"])\napp.include_router(risk.router, prefix=\"/api/v1/risk\", tags=[\"Risk\"])\n\n@app.get(\"/health\")\nasync def health_check():\n    \"\"\"Health check endpoint.\"\"\"\n    return {\"status\": \"healthy\", \"version\": \"1.0.0\"}\n\nif __name__ == \"__main__\":\n    uvicorn.run(\n        \"main:app\",\n        host=\"0.0.0.0\",\n        port=8000,\n        reload=settings.debug\n    )\n</code></pre>"},{"location":"python-guidelines/#api-endpoints","title":"API Endpoints","text":"<pre><code># ml_server/api/ocr.py\nfrom fastapi import APIRouter, HTTPException, UploadFile, File, Depends\nfrom pydantic import BaseModel, Field\nfrom typing import Dict, List, Optional\nimport asyncio\n\nfrom ml_server.models.ocr_model import OCRModel\nfrom ml_server.services.document_processor import DocumentProcessor\nfrom ml_server.utils.dependencies import get_ocr_model, get_document_processor\n\nrouter = APIRouter()\n\nclass OCRRequest(BaseModel):\n    \"\"\"OCR processing request.\"\"\"\n    document_type: str = Field(..., description=\"Type of document (pan, aadhar, etc.)\")\n    confidence_threshold: float = Field(0.8, ge=0.0, le=1.0)\n    extract_fields: bool = Field(True, description=\"Whether to extract specific fields\")\n\nclass OCRResponse(BaseModel):\n    \"\"\"OCR processing response.\"\"\"\n    extracted_text: str\n    confidence: float\n    fields: Optional[Dict[str, str]] = None\n    processing_time: float\n\n@router.post(\"/process\", response_model=OCRResponse)\nasync def process_document(\n    file: UploadFile = File(...),\n    request: OCRRequest = Depends(),\n    ocr_model: OCRModel = Depends(get_ocr_model),\n    processor: DocumentProcessor = Depends(get_document_processor)\n) -&gt; OCRResponse:\n    \"\"\"Process document through OCR pipeline.\"\"\"\n\n    # Validate file\n    if not file.content_type.startswith(('image/', 'application/pdf')):\n        raise HTTPException(\n            status_code=400,\n            detail=\"Unsupported file type. Only images and PDFs are allowed.\"\n        )\n\n    try:\n        # Process document\n        start_time = asyncio.get_event_loop().time()\n\n        result = await processor.process_document(\n            file=file,\n            document_type=request.document_type,\n            confidence_threshold=request.confidence_threshold\n        )\n\n        processing_time = asyncio.get_event_loop().time() - start_time\n\n        return OCRResponse(\n            extracted_text=result.text,\n            confidence=result.confidence,\n            fields=result.fields if request.extract_fields else None,\n            processing_time=processing_time\n        )\n\n    except Exception as e:\n        logger.error(f\"OCR processing failed: {e}\")\n        raise HTTPException(status_code=500, detail=\"OCR processing failed\")\n</code></pre>"},{"location":"python-guidelines/#ml-model-development","title":"\ud83e\udde0 ML Model Development","text":""},{"location":"python-guidelines/#base-model-class","title":"Base Model Class","text":"<pre><code># ml_server/models/base.py\nfrom abc import ABC, abstractmethod\nfrom pathlib import Path\nfrom typing import Any, Dict, Optional\nimport pickle\nimport joblib\nimport numpy as np\n\nclass BaseModel(ABC):\n    \"\"\"Base class for all ML models.\"\"\"\n\n    def __init__(self, model_path: Path, model_name: str):\n        self.model_path = model_path\n        self.model_name = model_name\n        self._model: Optional[Any] = None\n        self._is_loaded = False\n\n    @abstractmethod\n    def preprocess(self, data: Any) -&gt; np.ndarray:\n        \"\"\"Preprocess input data for model.\"\"\"\n        pass\n\n    @abstractmethod\n    def predict(self, features: np.ndarray) -&gt; Dict[str, Any]:\n        \"\"\"Make predictions using the model.\"\"\"\n        pass\n\n    @abstractmethod\n    def postprocess(self, predictions: np.ndarray) -&gt; Dict[str, Any]:\n        \"\"\"Postprocess model predictions.\"\"\"\n        pass\n\n    def load_model(self) -&gt; None:\n        \"\"\"Load the ML model from disk.\"\"\"\n        if self._is_loaded:\n            return\n\n        try:\n            if self.model_path.suffix == '.pkl':\n                with open(self.model_path, 'rb') as f:\n                    self._model = pickle.load(f)\n            elif self.model_path.suffix == '.joblib':\n                self._model = joblib.load(self.model_path)\n            else:\n                raise ValueError(f\"Unsupported model format: {self.model_path.suffix}\")\n\n            self._is_loaded = True\n            logger.info(f\"Model {self.model_name} loaded successfully\")\n\n        except Exception as e:\n            logger.error(f\"Failed to load model {self.model_name}: {e}\")\n            raise ModelLoadError(f\"Failed to load model: {e}\")\n\n    def is_loaded(self) -&gt; bool:\n        \"\"\"Check if model is loaded.\"\"\"\n        return self._is_loaded\n</code></pre>"},{"location":"python-guidelines/#specific-model-implementation","title":"Specific Model Implementation","text":"<pre><code># ml_server/models/risk_model.py\nimport numpy as np\nimport pandas as pd\nfrom typing import Dict, List, Any\nfrom pathlib import Path\n\nfrom .base import BaseModel\n\nclass RiskModel(BaseModel):\n    \"\"\"Risk assessment model for loan applications.\"\"\"\n\n    def __init__(self, model_path: Path, feature_config_path: Path):\n        super().__init__(model_path, \"risk_model\")\n        self.feature_config_path = feature_config_path\n        self._feature_names: List[str] = []\n        self._feature_config: Dict[str, Any] = {}\n\n    def load_model(self) -&gt; None:\n        \"\"\"Load model and feature configuration.\"\"\"\n        super().load_model()\n\n        # Load feature configuration\n        with open(self.feature_config_path, 'r') as f:\n            self._feature_config = json.load(f)\n\n        self._feature_names = self._feature_config.get('features', [])\n\n    def preprocess(self, application_data: Dict[str, Any]) -&gt; np.ndarray:\n        \"\"\"Preprocess application data into features.\"\"\"\n        features = []\n\n        for feature_name in self._feature_names:\n            feature_config = self._feature_config['feature_definitions'][feature_name]\n\n            if feature_config['type'] == 'numerical':\n                value = application_data.get(feature_name, 0.0)\n                # Apply scaling if configured\n                if 'scaling' in feature_config:\n                    value = self._apply_scaling(value, feature_config['scaling'])\n                features.append(value)\n\n            elif feature_config['type'] == 'categorical':\n                value = application_data.get(feature_name, 'unknown')\n                # One-hot encoding\n                encoded = self._encode_categorical(value, feature_config['categories'])\n                features.extend(encoded)\n\n        return np.array(features).reshape(1, -1)\n\n    def predict(self, features: np.ndarray) -&gt; Dict[str, Any]:\n        \"\"\"Predict risk score and category.\"\"\"\n        if not self._is_loaded:\n            self.load_model()\n\n        # Get prediction\n        risk_score = self._model.predict_proba(features)[0][1]  # Probability of default\n        risk_category = self._categorize_risk(risk_score)\n\n        # Get feature importance for explanation\n        feature_importance = self._get_feature_importance(features)\n\n        return {\n            'risk_score': float(risk_score),\n            'risk_category': risk_category,\n            'confidence': self._calculate_confidence(features),\n            'feature_importance': feature_importance,\n            'model_version': self._get_model_version()\n        }\n\n    def postprocess(self, predictions: np.ndarray) -&gt; Dict[str, Any]:\n        \"\"\"Postprocess predictions (already handled in predict method).\"\"\"\n        return predictions\n\n    def _categorize_risk(self, risk_score: float) -&gt; str:\n        \"\"\"Categorize risk score into risk levels.\"\"\"\n        if risk_score &lt; 0.3:\n            return \"low\"\n        elif risk_score &lt; 0.7:\n            return \"medium\"\n        else:\n            return \"high\"\n\n    def _calculate_confidence(self, features: np.ndarray) -&gt; float:\n        \"\"\"Calculate model confidence in prediction.\"\"\"\n        # Implementation depends on model type\n        probabilities = self._model.predict_proba(features)[0]\n        return float(max(probabilities))\n\n    def _get_feature_importance(self, features: np.ndarray) -&gt; Dict[str, float]:\n        \"\"\"Get feature importance for explanation.\"\"\"\n        if hasattr(self._model, 'feature_importances_'):\n            importance = self._model.feature_importances_\n            return dict(zip(self._feature_names, importance.tolist()))\n        return {}\n</code></pre>"},{"location":"python-guidelines/#error-handling","title":"\ud83d\udd27 Error Handling","text":""},{"location":"python-guidelines/#custom-exceptions","title":"Custom Exceptions","text":"<pre><code># ml_server/utils/exceptions.py\nclass MetisMLError(Exception):\n    \"\"\"Base exception for Metis ML services.\"\"\"\n    pass\n\nclass ModelLoadError(MetisMLError):\n    \"\"\"Raised when model loading fails.\"\"\"\n    pass\n\nclass InvalidDocumentError(MetisMLError):\n    \"\"\"Raised when document is invalid or unsupported.\"\"\"\n    pass\n\nclass ProcessingError(MetisMLError):\n    \"\"\"Raised when processing fails.\"\"\"\n    pass\n\nclass FeatureExtractionError(MetisMLError):\n    \"\"\"Raised when feature extraction fails.\"\"\"\n    pass\n</code></pre>"},{"location":"python-guidelines/#error-handling-patterns","title":"Error Handling Patterns","text":"<pre><code>import logging\nfrom typing import Optional\nfrom fastapi import HTTPException\n\nlogger = logging.getLogger(__name__)\n\nasync def safe_process_document(\n    file_path: Path,\n    processor: DocumentProcessor\n) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"Safely process document with error handling.\"\"\"\n    try:\n        result = await processor.process(file_path)\n        return result\n\n    except InvalidDocumentError as e:\n        logger.warning(f\"Invalid document {file_path}: {e}\")\n        raise HTTPException(status_code=400, detail=str(e))\n\n    except ModelLoadError as e:\n        logger.error(f\"Model loading failed: {e}\")\n        raise HTTPException(status_code=503, detail=\"Service temporarily unavailable\")\n\n    except ProcessingError as e:\n        logger.error(f\"Processing failed for {file_path}: {e}\")\n        raise HTTPException(status_code=500, detail=\"Processing failed\")\n\n    except Exception as e:\n        logger.error(f\"Unexpected error processing {file_path}: {e}\")\n        raise HTTPException(status_code=500, detail=\"Internal server error\")\n\n# Retry decorator\nimport asyncio\nfrom functools import wraps\n\ndef retry_async(max_attempts: int = 3, delay: float = 1.0):\n    \"\"\"Retry decorator for async functions.\"\"\"\n    def decorator(func):\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            last_exception = None\n\n            for attempt in range(max_attempts):\n                try:\n                    return await func(*args, **kwargs)\n                except Exception as e:\n                    last_exception = e\n                    if attempt &lt; max_attempts - 1:\n                        await asyncio.sleep(delay * (2 ** attempt))\n                        logger.warning(f\"Attempt {attempt + 1} failed, retrying: {e}\")\n                    else:\n                        logger.error(f\"All {max_attempts} attempts failed: {e}\")\n\n            raise last_exception\n        return wrapper\n    return decorator\n</code></pre>"},{"location":"python-guidelines/#testing","title":"\ud83e\uddea Testing","text":""},{"location":"python-guidelines/#test-structure","title":"Test Structure","text":"<pre><code># tests/test_models/test_risk_model.py\nimport pytest\nimport numpy as np\nfrom pathlib import Path\nfrom unittest.mock import Mock, patch\n\nfrom ml_server.models.risk_model import RiskModel\nfrom ml_server.utils.exceptions import ModelLoadError\n\nclass TestRiskModel:\n    \"\"\"Test suite for RiskModel.\"\"\"\n\n    @pytest.fixture\n    def sample_model_path(self, tmp_path):\n        \"\"\"Create a sample model file.\"\"\"\n        model_path = tmp_path / \"risk_model.pkl\"\n        # Create mock model file\n        return model_path\n\n    @pytest.fixture\n    def sample_feature_config(self, tmp_path):\n        \"\"\"Create sample feature configuration.\"\"\"\n        config_path = tmp_path / \"features.json\"\n        config = {\n            \"features\": [\"income\", \"age\", \"employment_type\"],\n            \"feature_definitions\": {\n                \"income\": {\"type\": \"numerical\", \"scaling\": {\"method\": \"standard\"}},\n                \"age\": {\"type\": \"numerical\"},\n                \"employment_type\": {\"type\": \"categorical\", \"categories\": [\"salaried\", \"self_employed\"]}\n            }\n        }\n        with open(config_path, 'w') as f:\n            json.dump(config, f)\n        return config_path\n\n    def test_model_initialization(self, sample_model_path, sample_feature_config):\n        \"\"\"Test model initialization.\"\"\"\n        model = RiskModel(sample_model_path, sample_feature_config)\n        assert model.model_path == sample_model_path\n        assert model.model_name == \"risk_model\"\n        assert not model.is_loaded()\n\n    @patch('ml_server.models.risk_model.joblib.load')\n    def test_model_loading_success(self, mock_load, sample_model_path, sample_feature_config):\n        \"\"\"Test successful model loading.\"\"\"\n        mock_model = Mock()\n        mock_load.return_value = mock_model\n\n        model = RiskModel(sample_model_path, sample_feature_config)\n        model.load_model()\n\n        assert model.is_loaded()\n        mock_load.assert_called_once()\n\n    def test_model_loading_failure(self, sample_feature_config, tmp_path):\n        \"\"\"Test model loading failure.\"\"\"\n        nonexistent_path = tmp_path / \"nonexistent.pkl\"\n        model = RiskModel(nonexistent_path, sample_feature_config)\n\n        with pytest.raises(ModelLoadError):\n            model.load_model()\n\n    def test_preprocess_valid_data(self, sample_model_path, sample_feature_config):\n        \"\"\"Test preprocessing with valid data.\"\"\"\n        model = RiskModel(sample_model_path, sample_feature_config)\n\n        application_data = {\n            \"income\": 50000.0,\n            \"age\": 30,\n            \"employment_type\": \"salaried\"\n        }\n\n        features = model.preprocess(application_data)\n        assert isinstance(features, np.ndarray)\n        assert features.shape[0] == 1  # Single sample\n\n    @pytest.mark.asyncio\n    async def test_predict_integration(self, sample_model_path, sample_feature_config):\n        \"\"\"Integration test for prediction.\"\"\"\n        with patch('ml_server.models.risk_model.joblib.load') as mock_load:\n            # Mock model with predict_proba method\n            mock_model = Mock()\n            mock_model.predict_proba.return_value = np.array([[0.3, 0.7]])\n            mock_model.feature_importances_ = np.array([0.5, 0.3, 0.2])\n            mock_load.return_value = mock_model\n\n            model = RiskModel(sample_model_path, sample_feature_config)\n\n            application_data = {\n                \"income\": 50000.0,\n                \"age\": 30,\n                \"employment_type\": \"salaried\"\n            }\n\n            features = model.preprocess(application_data)\n            result = model.predict(features)\n\n            assert \"risk_score\" in result\n            assert \"risk_category\" in result\n            assert \"confidence\" in result\n            assert 0.0 &lt;= result[\"risk_score\"] &lt;= 1.0\n</code></pre>"},{"location":"python-guidelines/#test-configuration","title":"Test Configuration","text":"<pre><code># tests/conftest.py\nimport pytest\nimport asyncio\nfrom pathlib import Path\nfrom fastapi.testclient import TestClient\n\nfrom ml_server.main import app\n\n@pytest.fixture\ndef client():\n    \"\"\"Test client for FastAPI app.\"\"\"\n    return TestClient(app)\n\n@pytest.fixture\ndef sample_document(tmp_path):\n    \"\"\"Create a sample document for testing.\"\"\"\n    doc_path = tmp_path / \"sample.pdf\"\n    doc_path.write_bytes(b\"sample pdf content\")\n    return doc_path\n\n@pytest.fixture(scope=\"session\")\ndef event_loop():\n    \"\"\"Create an instance of the default event loop for the test session.\"\"\"\n    loop = asyncio.get_event_loop_policy().new_event_loop()\n    yield loop\n    loop.close()\n</code></pre>"},{"location":"python-guidelines/#performance-optimization","title":"\u26a1 Performance Optimization","text":""},{"location":"python-guidelines/#async-programming","title":"Async Programming","text":"<pre><code>import asyncio\nimport aiofiles\nfrom concurrent.futures import ThreadPoolExecutor\nfrom typing import List\n\n# Async file operations\nasync def read_document_async(file_path: Path) -&gt; bytes:\n    \"\"\"Read document asynchronously.\"\"\"\n    async with aiofiles.open(file_path, 'rb') as f:\n        return await f.read()\n\n# CPU-bound operations in thread pool\nexecutor = ThreadPoolExecutor(max_workers=4)\n\nasync def process_documents_parallel(documents: List[Path]) -&gt; List[Dict[str, Any]]:\n    \"\"\"Process multiple documents in parallel.\"\"\"\n    tasks = []\n\n    for doc_path in documents:\n        task = asyncio.create_task(process_single_document(doc_path))\n        tasks.append(task)\n\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n\n    # Handle exceptions\n    processed_results = []\n    for i, result in enumerate(results):\n        if isinstance(result, Exception):\n            logger.error(f\"Failed to process {documents[i]}: {result}\")\n        else:\n            processed_results.append(result)\n\n    return processed_results\n\nasync def cpu_intensive_task(data: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Run CPU-intensive task in thread pool.\"\"\"\n    loop = asyncio.get_event_loop()\n    return await loop.run_in_executor(executor, _cpu_intensive_operation, data)\n\ndef _cpu_intensive_operation(data: np.ndarray) -&gt; np.ndarray:\n    \"\"\"CPU-intensive operation that runs in thread pool.\"\"\"\n    # Heavy computation here\n    return np.dot(data, data.T)\n</code></pre>"},{"location":"python-guidelines/#memory-management","title":"Memory Management","text":"<pre><code>import gc\nfrom contextlib import contextmanager\n\n@contextmanager\ndef memory_cleanup():\n    \"\"\"Context manager for memory cleanup.\"\"\"\n    try:\n        yield\n    finally:\n        gc.collect()\n\n# Efficient data processing\ndef process_large_dataset(data_path: Path, batch_size: int = 1000) -&gt; None:\n    \"\"\"Process large dataset in batches.\"\"\"\n    with memory_cleanup():\n        for chunk in pd.read_csv(data_path, chunksize=batch_size):\n            # Process chunk\n            processed_chunk = process_chunk(chunk)\n\n            # Save results\n            save_processed_chunk(processed_chunk)\n\n            # Clear memory\n            del chunk, processed_chunk\n            gc.collect()\n</code></pre>"},{"location":"python-guidelines/#logging-monitoring","title":"\ud83d\udcca Logging &amp; Monitoring","text":""},{"location":"python-guidelines/#structured-logging","title":"Structured Logging","text":"<pre><code># ml_server/utils/logging.py\nimport logging\nimport json\nfrom typing import Any, Dict\nfrom datetime import datetime\n\nclass StructuredFormatter(logging.Formatter):\n    \"\"\"Structured JSON formatter for logs.\"\"\"\n\n    def format(self, record: logging.LogRecord) -&gt; str:\n        log_entry = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"level\": record.levelname,\n            \"logger\": record.name,\n            \"message\": record.getMessage(),\n            \"module\": record.module,\n            \"function\": record.funcName,\n            \"line\": record.lineno\n        }\n\n        # Add extra fields\n        if hasattr(record, 'extra_fields'):\n            log_entry.update(record.extra_fields)\n\n        return json.dumps(log_entry)\n\ndef get_logger(name: str) -&gt; logging.Logger:\n    \"\"\"Get configured logger.\"\"\"\n    logger = logging.getLogger(name)\n\n    if not logger.handlers:\n        handler = logging.StreamHandler()\n        handler.setFormatter(StructuredFormatter())\n        logger.addHandler(handler)\n        logger.setLevel(logging.INFO)\n\n    return logger\n\n# Usage\nlogger = get_logger(__name__)\n\ndef process_with_logging(data: Dict[str, Any]) -&gt; Dict[str, Any]:\n    \"\"\"Process data with structured logging.\"\"\"\n    logger.info(\n        \"Starting data processing\",\n        extra={'extra_fields': {'data_size': len(data), 'operation': 'process'}}\n    )\n\n    try:\n        result = process_data(data)\n        logger.info(\n            \"Data processing completed successfully\",\n            extra={'extra_fields': {'result_size': len(result)}}\n        )\n        return result\n\n    except Exception as e:\n        logger.error(\n            \"Data processing failed\",\n            extra={'extra_fields': {'error': str(e), 'data_keys': list(data.keys())}}\n        )\n        raise\n</code></pre>"},{"location":"python-guidelines/#code-quality-tools","title":"\ud83d\udd0d Code Quality Tools","text":""},{"location":"python-guidelines/#linting-configuration","title":"Linting Configuration","text":"<pre><code># pyproject.toml\n[tool.black]\nline-length = 88\ntarget-version = ['py311']\ninclude = '\\.pyi?$'\n\n[tool.isort]\nprofile = \"black\"\nmulti_line_output = 3\nline_length = 88\n\n[tool.pylint.messages_control]\ndisable = \"C0330, C0326\"\n\n[tool.mypy]\npython_version = \"3.11\"\nwarn_return_any = true\nwarn_unused_configs = true\ndisallow_untyped_defs = true\n\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\npython_files = [\"test_*.py\"]\npython_classes = [\"Test*\"]\npython_functions = [\"test_*\"]\naddopts = \"-v --cov=ml_server --cov-report=html\"\n</code></pre>"},{"location":"python-guidelines/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<pre><code># .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/psf/black\n    rev: 23.9.1\n    hooks:\n      - id: black\n\n  - repo: https://github.com/pycqa/isort\n    rev: 5.12.0\n    hooks:\n      - id: isort\n\n  - repo: https://github.com/pycqa/flake8\n    rev: 6.1.0\n    hooks:\n      - id: flake8\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.6.1\n    hooks:\n      - id: mypy\n</code></pre> <p>These guidelines ensure consistent, maintainable, and performant Python code across the Metis ML services and data processing components.</p>"}]}